{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">SIT 112 - Data Science Concepts - Assignment 2</span>\n",
    "\n",
    "---\n",
    "Lecturer: Truyen Tran | truyen.tran@deakin.edu.au<br />\n",
    "\n",
    "School of Information Technology, <br />\n",
    "Deakin University, VIC 3215, Australia.\n",
    "\n",
    "### <span style=\"color:#0b486b\">Due: 5pm, 11th May 2018 </span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Instructions</span>\n",
    "\n",
    "This notebook has been prepared for you to complete Assignment 2. Some sections have been partially completed  to help you get started. **The total marks for this notebook is 200**.\n",
    "\n",
    "* Before you start, read the entire notebook carefully to understand what you need to do. You should also refer to the main instructions in *Assignment2_instructions.pdf*  to know what else you need to complete for this assignment as well submission instruction. <br><br>\n",
    "\n",
    "* For each cell marked with **#YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL**, there will be places where you **must** supply your own codes when instructed. <br><br>\n",
    "\n",
    "\n",
    "### Submission\n",
    "\n",
    "You are required to submit **five** files: <br><br>\n",
    "\n",
    "* The source of your solution notebook: **[groupID]_assignment2_solution.ipynb**\n",
    "* An exported version of your output: **[groupID]_assignment2_output.html**  \n",
    "* Three json data files storing tweets collected for three keywords, named **[groupID]_w1.json**, **[groupID]_w2.json**, **[groupID]_w3.json** where **w1, w2, w3** are the three keywords you selected.\n",
    "    \n",
    "\n",
    "\n",
    "As you go through this notebook:\n",
    "\n",
    "* markdown cells marked with **Note** mean description sections.\n",
    "* markdown cells marked with **Instruction** mean the instructions given to you to complete the designated section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 1: Crawling and Storing Tweet Data for Australia</span>\n",
    "\n",
    "\n",
    "The first part of the assignment examines your skills and knowledge to query tweets and store them in json files. For **each** selected keyword, your tasks are:\n",
    "\n",
    "* Crawl all tweets contain this keyword written in English and geocoded within Australia.\n",
    "* Store the tweets collected into json files.\n",
    "\n",
    "***Follow the instructions below to complete your task***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The following packages will be required for this assignment. If you need to import more packages, you might append them to the end of the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import packages needed for processing\n",
    "'''\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from TwitterAPI import TwitterAPI # in case you need to install this package, see practical 6\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import requests\n",
    "\n",
    "# disabling urllib3 warnings\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "If you need add any additional packages, then add them below\n",
    "'''\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 1.1**. Enter your selected keywords to the variable **keywords** below.\n",
    "\n",
    "[**Total mark: 3**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Enter the list of three keywords you selected to the variables keywords below\n",
    "e.g. keywords = [\"game\",\"bike\",\"fiction\"]\n",
    "'''\n",
    "\n",
    "keywords = [\"game\",\"bike\",\"fiction\"] # INSERT YOUR CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Instruction 1.2**. Before you can perform a query to Twitter API, you need to supply authentication information. Practical sessions 6 and 7 show you how to obtain this information. **Your task is to supply the authentication information in the cell below**.\n",
    "\n",
    "**Note**: You might decide to regenerate this authentication from the pracs if you would like too. <span style=\"color:red\">After the assignment has been marked, you are strongly recommended to regenerate this authentication information from your account to maintain your privacy.</span> \n",
    "\n",
    "\n",
    "[**Total mark: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "# Twitter API credentials \n",
    "CONSUMER_KEY =  \"ihqmqR1jJQ1g0I5IKcEKrbHr1\"#ENTER YOUR CONSUMER_KEY\n",
    "CONSUMER_SECRET = \"oBYqs6yMNlbPC7acVD80W9HQQTtw27oDa7CRzzJbI5sWMKQ77s\"#ENTER YOUR CONSUMER_SECRET\n",
    "OAUTH_TOKEN = \"939424711028740097-KgPDxQn02juU9t9XsmdAPzzvdKVqsLL\" #ENTER YOUR OAUTH_TOKEN\n",
    "OAUTH_TOKEN_SECRET = \"b3whAx9mywsj9FpFWMSzAT5T5o4U5YUAMSU0PNBRZRA8B\"  #ENTER YOUR OAUTH_TOKEN_SECRET\n",
    "\n",
    "# Authonticating with your application credentials\n",
    "api = TwitterAPI(CONSUMER_KEY,\n",
    "                 CONSUMER_SECRET,\n",
    "                 OAUTH_TOKEN,\n",
    "                 OAUTH_TOKEN_SECRET)\n",
    "                 # INSERT YOUR CODE HERE\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: As you have learned from the pracical sessions, to perform a query from Twitter API for a particular geo-coded location you need a center point and a radius. The center point is specified by its (latitude,longitute) pair. **The information below has been given to you to perform the query in the subsequent tasks**. **Do not** modify these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo coordinations of the desired place\n",
    "AUS_LAT = -24.396176\n",
    "AUS_LONG = 133.247614\n",
    "AUS_RADIUS = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 1.3**. For each keyword, you are required to crawl at least **500** tweets using the Twitter API. However, as you have learned from the practical sessions, each query will return a maximum of only **100** tweets. Therefore, subsequent query **must** use the maximum Tweet ID from the previous batch to crawl the next lot.\n",
    "\n",
    "The following function, called ***retrieve_tweets()***, has been **partially** implemented to automatically download tweets until it reaches the maximum number of tweets needed. \n",
    "\n",
    "For example, a function call\n",
    "```\n",
    "retrieve_tweets(api,'car',50,500)\n",
    "```\n",
    "will attempt to crawl a total of at least 500 tweets that contains the word 'car'. Within each single query, it will attempt to obtain 50 tweets. For this assignment, by default we will query within Australian region specified by the latitute, longitude and radius specified before.\n",
    "\n",
    "**Your task is to walk through this function and enter your own codes where instructed to complete the function**.\n",
    "\n",
    "[**Total mark: 14**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "You will be required to insert your own codes to complete this function. \n",
    "Walk through this function and enter your own codes where instructed.\n",
    "'''\n",
    "def retrieve_tweets(api, keyword, batch_count, total_count):\n",
    "    \"\"\"\n",
    "    collects tweets using the Twitter search API\n",
    "    \n",
    "    api:         Twitter API instance\n",
    "    keyword:     search keyword\n",
    "    batch_count: maximum number of tweets to collect per each request\n",
    "    total_count: maximum number of tweets in total\n",
    "    \"\"\"\n",
    "    \n",
    "    # the collection of tweets to be returned\n",
    "    tweets = []\n",
    "    \n",
    "    # the number of tweets within a single query\n",
    "    batch_count = str(batch_count)\n",
    "    \n",
    "    '''\n",
    "    You are required to insert your own code where instructed to perform the first query to Twitter API.\n",
    "    Hint: revise the practical session on Twitter API on how to perform query to Twitter API.\n",
    "    '''\n",
    "    # per the first query, to obtain max_id_str which will be used later to query sub\n",
    "    resp = api.request('search/tweets', {'q': keyword,\n",
    "                                         'count': '100',#INSERT YOUR CODE\n",
    "                                         'lang':'en',\n",
    "                                         'result_type':'recent',\n",
    "                                         'geocode':'{},{},{}mi'.format(AUS_LAT, AUS_LONG,AUS_RADIUS)\n",
    "                                        }\n",
    "                      )\n",
    "    \n",
    "    # store the tweets in a list\n",
    "    tweets += resp.json()['statuses']\n",
    "    \n",
    "    # find the max_id_str for the next batch\n",
    "    ids = [tweet['id'] for tweet in tweets]\n",
    "    max_id_str = str(min(ids))\n",
    "\n",
    "    # loop until as many tweets as total_count is collected\n",
    "    number_of_tweets = len(tweets)\n",
    "    while number_of_tweets < total_count:\n",
    "        print(\"{} tweets are collected for keyword {}. Last tweet created at {}\".format(number_of_tweets, \n",
    "                                                                                        keyword, \n",
    "                                                                                        tweets[number_of_tweets-1]['created_at']))\n",
    "        resp = api.request('search/tweets', {'q': keyword,\n",
    "                                             'count':'100',\n",
    "                                             'lang':'en',\n",
    "                                             'result_type':'recent',#INSERT YOUR CODE\n",
    "                                             'max_id':'id' , #INSERT YOUR CODE\n",
    "                                             'geocode':'{},{},{}mi'.format(AUS_LAT, AUS_LONG,AUS_RADIUS)\n",
    "                                             #INSERT YOUR CODE\n",
    "                                            }\n",
    "                          )\n",
    "\n",
    "        tweets += resp.json()['statuses']\n",
    "        ids = [tweet['id'] for tweet in tweets]\n",
    "        max_id_str = str(min(ids))\n",
    "        number_of_tweets = len(tweets)\n",
    "        \n",
    "    print(\"{} tweets are collected for keyword {}. Last tweet created at {}\".format(number_of_tweets, \n",
    "                                                                                    keyword, \n",
    "                                                                                    tweets[number_of_tweets-1]['created_at']))\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 1.4**. After having defined the ***retrieve_tweets()*** function above, you are now ready to use this function to collect your tweets. Your task is to write the code to perform three function calls, each corresponds to one keyword. And, you are required to collect at least **500** tweets for each key word.\n",
    "\n",
    "[**Total mark: 9**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tweets are collected for keyword game. Last tweet created at Wed May 09 04:00:19 +0000 2018\n",
      "200 tweets are collected for keyword game. Last tweet created at Wed May 09 04:00:23 +0000 2018\n",
      "300 tweets are collected for keyword game. Last tweet created at Wed May 09 04:00:23 +0000 2018\n",
      "400 tweets are collected for keyword game. Last tweet created at Wed May 09 04:00:23 +0000 2018\n",
      "500 tweets are collected for keyword game. Last tweet created at Wed May 09 04:00:23 +0000 2018\n",
      "100 tweets are collected for keyword bike. Last tweet created at Tue May 08 21:55:04 +0000 2018\n",
      "200 tweets are collected for keyword bike. Last tweet created at Tue May 08 21:55:04 +0000 2018\n",
      "300 tweets are collected for keyword bike. Last tweet created at Tue May 08 21:55:04 +0000 2018\n",
      "400 tweets are collected for keyword bike. Last tweet created at Tue May 08 21:55:04 +0000 2018\n",
      "500 tweets are collected for keyword bike. Last tweet created at Tue May 08 21:55:04 +0000 2018\n",
      "100 tweets are collected for keyword fiction. Last tweet created at Tue May 08 21:08:31 +0000 2018\n",
      "200 tweets are collected for keyword fiction. Last tweet created at Tue May 08 21:08:31 +0000 2018\n",
      "300 tweets are collected for keyword fiction. Last tweet created at Tue May 08 21:08:31 +0000 2018\n",
      "400 tweets are collected for keyword fiction. Last tweet created at Tue May 08 21:08:31 +0000 2018\n",
      "500 tweets are collected for keyword fiction. Last tweet created at Tue May 08 21:08:31 +0000 2018\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Your task is to write the code to perform three function calls, each corresponds to one keyword. \n",
    "And, you are required to collect at least 500 tweets for each key word.\n",
    "'''\n",
    "\n",
    "# Collecting the tweets for three assigned keywords, \n",
    "# Your function call should look like this:  retrieve_tweets(api,'keyword',single_count,total_count)\n",
    "\n",
    "k1_tweets = retrieve_tweets(api, 'game', 50, 500)               #INSERT YOUR CODE HERE\n",
    "k2_tweets = retrieve_tweets(api, 'bike', 50, 500)#INSERT YOUR CODE HERE\n",
    "k3_tweets = retrieve_tweets(api, 'fiction', 50, 500)#INSERT YOUR CODE HERE\n",
    "\n",
    "# PLEASE NOTE THAT IF YOU RUN THIS CELL, IT MIGHT TAKE A WHILE TO DOWNLOAD ALL THE TWEETS REQUIRED.\n",
    "# MAKE SURE THAT YOU WAIT UNTILL THE CELL FINISHES RUNNING."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 1.5**. To verify the downloading process, write your code to print out the number of tweets which has been collected for each keyword.\n",
    "\n",
    "[**Total mark: 3**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your code to print the number of tweets have been collected for each keyword\n",
    "'''\n",
    "# INSERT OUR CODE HERE\n",
    "print(len(k1_tweets))\n",
    "print(len(k2_tweets))\n",
    "print(len(k3_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Each tweet is stored in a dictionary where its keywords are fields in the tweet and values are the information of the fields. The cell below print the type of a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Data type of tweets\n",
    "print(type(k1_tweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 1.6**.  To examine what the tweets look like, in the cell below write your code to print out all fields of the first tweet in `k1_tweets` and print out the text of the first tweet collected for each keyword.\n",
    "\n",
    "[**Total mark: 6**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'metadata', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'retweeted_status', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'lang'])\n",
      "\n",
      "The text of the first tweet for \"game\":\n",
      "\n",
      "RT @TheoHarrison9: Oh please, now slimy shorten is hinting the High Court moved the goal posts.\n",
      "Trouble is,even if they did, Ludlum startin…\n",
      "\n",
      "The text of the first tweet for \"bike\":\n",
      "\n",
      "@Cameron_Kirby plenty of share ones in Melbourne to practice on. It's like riding a bike. An acoustic motorbike.\n",
      "\n",
      "The text of the first tweet for \"fiction\":\n",
      "\n",
      "@ElliotLangerman A good point, although I found non-fiction books were slightly better than fiction as audio books.\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your code to print out all fields of the first tweet\n",
    "Hint: You might want to use method keys() of the dictionary\n",
    "'''# INSERT YOUR CODE HERE\n",
    "\n",
    "print(k1_tweets[0].keys())\n",
    "'''\n",
    "Write your code to print out the text of the first  tweet collected for each keyword.\n",
    "'''\n",
    "\n",
    "print(\"\\nThe text of the first tweet for \\\"{}\\\":\\n\".format(keywords[0]))\n",
    "print(k1_tweets[0]['text'])# INSERT YOUR CODE HERE\n",
    "\n",
    "print('\\nThe text of the first tweet for \\\"{}\\\":\\n'.format(keywords[1]))\n",
    "print(k2_tweets[0]['text'])\n",
    "          # INSERT YOUR CODE HERE\n",
    "\n",
    "print('\\nThe text of the first tweet for \\\"{}\\\":\\n'.format(keywords[2]))\n",
    "print(k3_tweets[0]['text'])# INSERT YOUR CODE HER3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. When collecting data from the Internet, such as Twitter, it is important that we store the data collected in an appropriate format for later data analysis task. We have learned that json is a poplular lightweight data format that can be handy to store unstructured data. For example, with NoSQL we can directly query these files in a 'scaling out' fashion. These technologies are representative features of Big Data Analytics.\n",
    "\n",
    "The following function has been designed for you to save an object which is a list of dictionaries (such as k1_tweets variable) to a json file. **You will need this function for your next task**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(obj, filename):\n",
    "    \"\"\"\n",
    "    saves a list of dictionaries into a json file\n",
    "    \n",
    "    obj: list of dictionaries\n",
    "    filename: filename\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(obj, fp, indent=4, sort_keys=True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 1.7**. Use the function ***save_to_json()*** defined above, for each collection of tweets you have crawled for each keyword, save them into a file named **w.json** where **w** is the keyword.\n",
    "\n",
    "For example, if your keywords are 'w1', 'w2' and 'w3', then your code must generate three file w1.json, w2.json and w3.json. **Important: you must submit these files together with your notebook solution**.\n",
    "\n",
    "[**Total mark: 9**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Use the save_to_json() function defined above, for the collection of tweets \n",
    "you have crawled for each keyword, save them into a file named w.json where w is the keyword.\n",
    "'''\n",
    "# saving the tweets in three json files, one for each keyword\n",
    "#INSERT YOUR CODE HERE\n",
    "save_to_json(k1_tweets, 'game.json')\n",
    "save_to_json(k2_tweets, 'bike.json')\n",
    "save_to_json(k3_tweets, 'fiction.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                                     END OF PART 1\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Analytics\n",
    "\n",
    "The second part of this assignment will examine your skills and knowlege in data manipulation and analysis tasks. It includes three main components:\n",
    "\n",
    "**Part 2A**. For each keyword, you will be required to load the tweets from your saved json files (from Part 1) and filter out all tweets that are too short.\n",
    "\n",
    "**Part 2B**. Using your knowledge from practical session 5 to 7 to construct the term-by-document matrix for the tweets and perform visualisation tasks to understand them.\n",
    "\n",
    "**Part 2C**. Applying the Kmeans clustering algorithm to cluster your tweets and report the clustering results.\n",
    "\n",
    "***Follow the instructions below to complete your assigned tasks***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2A: Load and Filter Tweets from Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.1**. The following function, named ***read_json_file()***, has been partially implemented to load data from a json file. This function will be used later on to load three json files you have saved from Part 1. Your task is to insert your own code where instructed to complete this function.\n",
    "\n",
    "[**Total mark: 3**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Insert your own code where instructed to complete this function\n",
    "'''\n",
    "def read_json_file(filename):\n",
    "    \"\"\"\n",
    "    reads from a json file and saves the result in a list named data\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as fp:\n",
    "        d = json.load(fp)\n",
    "        data = d\n",
    "        # INSERT THE MISSING PIECE OF CODE HERE\n",
    "        return data     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.2**. Now use the ***read_json_file()*** function defined above, write three function calls to load data from three json files you have saved from Part 1.\n",
    "\n",
    "[**Total mark: 9**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write three function calls to load data from three json files you have saved from Part 1.\n",
    "'''\n",
    "\n",
    "k1_tweets  = read_json_file('game.json')# INSERT YOUR CODE HERE\n",
    "k2_tweets = read_json_file('bike.json')# INSERT YOUR CODE HERE\n",
    "k3_tweets = read_json_file('fiction.json')# INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.3**. To examine the number of tweets loaded from your data files, write your code to print out the number of tweets containes in three variables: ***k1_tweets, k2_tweets*** and ***k3_tweets***.\n",
    "\n",
    "[**Total mark: 3**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your code to print out the number of tweets containes in three variables: \n",
    "k1_tweets, k2_tweets and k3_tweets\n",
    "'''\n",
    "#INSERT YOUR CODE HERE\n",
    "print(len(k1_tweets))\n",
    "print(len(k2_tweets))\n",
    "print(len(k3_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. When analysing tweets and text documents in general, an important analytics skill is to pre-process and filter the data into the form that one can start to apply analytics methods to extract knowledge. \n",
    "\n",
    "Tweets that are too short might not be useful for analysis. We define that tweets having less than 50 characters are short and should be remove. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.4**. In this task, you need to filter all short tweets.\n",
    "\n",
    "1. Write a function called `is_short_tweet` that takes a tweet as an input and return True if the text of the tweet has less than 50 characters and False otherwise. **(6 marks)**\n",
    "\n",
    "2. Write your codes to remove all tweets that have less than 50 characters in variables ***k1_tweets***, ***k2_tweets*** and ***k3_tweets*** and store the results in the new variables ***k1_tweets_filtered***, ***k2_tweets_filtered*** and ***k3_tweets_filtered***, respectively. **(6 marks)**\n",
    "\n",
    "[**Total mark: 12**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "def is_short_tweet(tweet):\n",
    "    if len(tweet['text'])<50:\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "    '''\n",
    "    Check if the text of \"tweet\" has less than 50 characters\n",
    "    '''\n",
    "    # INSERT YOUR CODE HERE\n",
    "is_short_tweet(k1_tweets[420])    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 460\n",
      "500 470\n",
      "500 495\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your codes to remove all tweets which have less than 50 characters in variables \n",
    "k1_tweets, k2_tweets and k3_tweets and store the results in the new variables \n",
    "k1_tweets_filtered, k2_tweets_filtered and k3_tweets_filtered respectively\n",
    "'''\n",
    "\n",
    "k1_tweets_filtered = []\n",
    "for i, c in enumerate(k1_tweets):\n",
    "    if len(c['text'])<50:\n",
    "        c.clear\n",
    "    else:\n",
    "        k1_tweets_filtered.append(c)\n",
    "        \n",
    "k2_tweets_filtered = []\n",
    "for i, c in enumerate(k2_tweets):\n",
    "    if len(c['text'])<50:\n",
    "        c.clear\n",
    "    else:\n",
    "        k2_tweets_filtered.append(c)\n",
    "            \n",
    "k3_tweets_filtered = []\n",
    "for i, c in enumerate(k3_tweets):\n",
    "    if len(c['text'])<50:\n",
    "        c.clear\n",
    "    else:\n",
    "        k3_tweets_filtered.append(c)\n",
    "'''\n",
    "    Check if the text of \"tweet\" has less than 50 characters\n",
    "'''\n",
    "\n",
    "         \n",
    "         # INSERT YOUR CODE HERE\n",
    "\n",
    "         \n",
    "print(len(k1_tweets), len(k1_tweets_filtered))  \n",
    "print(len(k2_tweets), len(k2_tweets_filtered))\n",
    "print(len(k3_tweets), len(k3_tweets_filtered))\n",
    "\n",
    "\n",
    "# these lines below print the number of tweets for each keyword before and after filtered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.5**. For each keyword, print out the number of tweets that have been removed.\n",
    "\n",
    "[**Total mark: 3**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "30\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "For each keyword, print out the number of tweets that have been removed.\n",
    "'''\n",
    "print(len(k1_tweets) - len(k1_tweets_filtered))\n",
    "print(len(k2_tweets) - len(k2_tweets_filtered))\n",
    "print(len(k3_tweets) - len(k3_tweets_filtered))\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.6**. To examine what the tweets look like after being loaded from the data files and filtered, in the cell below write your code to print out the first **5** tweets for each keyword. \n",
    "\n",
    "You **must** use the variables ***k1_tweets_filtered, k2_tweets_filtered*** and ***k3_tweets_filtered*** which have stored the data after the filtering process for this task.\n",
    "\n",
    "[**Total mark: 3**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(k1_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 tweets for \"game\":\n",
      "\n",
      "0 RT @TheoHarrison9: Oh please, now slimy shorten is hinting the High Court moved the goal posts.\n",
      "Trouble is,even if they did, Ludlum startin…\n",
      "1 @HarfSerious You are getting ahead of yourself and you haven't even coached a game yet\n",
      "#bigshorts #bigego\n",
      "2 @Nboyz98 @madmuzz_196 @bbcmusic @DUALIPA Muzz you better order your lfc shirt in time for the game\n",
      "3 @AKRacingAus You guys have actually made it possible for me to play a game for longer than 20 minutes! And for that I thank you 💜\n",
      "4 RT @kloud_kat: @flyingpig32 @RicepirateMick Honestly, one of the best uses of Heaven's Door I've ever seen.\n",
      "\n",
      "The first 5 tweets for \"bike\":\n",
      "\n",
      "0 @Cameron_Kirby plenty of share ones in Melbourne to practice on. It's like riding a bike. An acoustic motorbike.\n",
      "1 New Atlas (nee Gizmag)... Vintage e-bike gets black-out looks and adventure-ready performance… https://t.co/cdClGWqAZk\n",
      "2 RT @curatorofkitsch: Checked out the #WW1 German ersatz (substitute) bike tyres while in one of the @AWMemorial collection stores today. Ru…\n",
      "3 RT @CarCarLaJenkins: My son is shocked and devastated, his new bike we picked up yesterday for him to do the great vic bike ride is damaged…\n",
      "4 RT @JoinTheDrive: The faster you go, the harder you hit. When you’re on your bike, you don’t have the same protection as a car, so you’ll a…\n",
      "\n",
      "The first 5 tweets for \"fiction\":\n",
      "\n",
      "0 @ElliotLangerman A good point, although I found non-fiction books were slightly better than fiction as audio books.\n",
      "1 RT @CHepworthAuthor: The Last Oracle: A Climate Fiction Thriller \n",
      "Click Here! https://t.co/AHsIp7CruP\n",
      "#climatefiction #sciencefiction #susp…\n",
      "2 RT @LamaJabr: The Last Oracle: A Climate Fiction Thriller by @CHepworthAuthor\n",
      "Click Here! https://t.co/U9FycxnSwa\n",
      "#climatefiction #sciencef…\n",
      "3 Truth is Stranger Than Fiction\n",
      "Source : Neet Onna to Shougaku 2-nensei https://t.co/3o1qp34G9N\n",
      "4 RT @LamaJabr: The Last Oracle: A Climate Fiction Thriller by @CHepworthAuthor\n",
      "Click Here! https://t.co/U9FycxnSwa\n",
      "#climatefiction #sciencef…\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your code to print out the first 5 tweets for each keyword.\n",
    "You must use the variables k1_tweets_filtered, k2_tweets_filtered and k3_tweets_filtered \n",
    "which have stored the data after the filtering process for this task.\n",
    "\n",
    "Hint: Using tweet['text'] for tweet in k1_tweets_filtered\n",
    "'''\n",
    "\n",
    "print('The first 5 tweets for \\\"{}\\\":\\n'.format(keywords[0]))\n",
    "for c, i in enumerate(range(5)):\n",
    "    print(c, k1_tweets_filtered[i]['text'])# INSERT YOUR CODE HERE\n",
    "\n",
    "print('\\nThe first 5 tweets for \\\"{}\\\":\\n'.format(keywords[1]))\n",
    "for c, i in enumerate(range(5)):\n",
    "    print(c, k2_tweets_filtered[i]['text'])# INSERT YOUR CODE HERE\n",
    "\n",
    "print('\\nThe first 5 tweets for \\\"{}\\\":\\n'.format(keywords[2]))\n",
    "for c, i in enumerate(range(5)):\n",
    "    print(c, k3_tweets_filtered[i]['text'])# INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2B: Constructing Term-by-Document Matrix\n",
    "\n",
    "As we have learned in our class, in text analytics and in general dealing with unstructured data, to start perform **computational** tasks such as computing the distance between two documents, we need to represent them in **numerical** formats. A popular technique we have learned is the bag-of-word representation and the term-by-document matrix, also known as the vector-space model.\n",
    "\n",
    "This part of the assignment will require you to construct the term-by-document matrix for the tweets stored in three variables ***k1_tweets_filtered***, ***k2_tweets_filtered*** and ***k3_tweets_filtered***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note.** Tweets are often not neat as you might have seen from early tasks. As tweet such as this \n",
    "```\n",
    "Happy shopping👗👚👠👜 (with Vivi and Irmalia at @infomog) — https://t.co/fUGO9Eex1r\n",
    "```\n",
    "might contain non-ASCII characters, emoticon, punctuations, etc. Building a bag-of-word representation **without** pre-processing the data can be ineffective. \n",
    "\n",
    "The following function ***pre_process()*** has been designed to preprocess the data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(s): return \"\".join(i for i in s if ord(i)<128)\n",
    "def pre_process(doc):\n",
    "    \"\"\"\n",
    "    pre-processes a doc\n",
    "      * Converts the tweet into lower case,\n",
    "      * removes the URLs,\n",
    "      * removes the punctuations\n",
    "      * tokenizes the tweet\n",
    "      * removes words less that 3 characters\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = doc.lower()\n",
    "    # getting rid of non ascii codes\n",
    "    doc = remove_non_ascii(doc)\n",
    "    \n",
    "    # replacing URLs\n",
    "    url_pattern = \"http://[^\\s]+|https://[^\\s]+|www.[^\\s]+|[^\\s]+\\.com|bit.ly/[^\\s]+\"\n",
    "    doc = re.sub(url_pattern, 'url', doc) \n",
    "\n",
    "    punctuation = r\"\\(|\\)|#|\\'|\\\"|-|:|\\\\|\\/|!|\\?|_|,|=|;|>|<|\\.|\\@\"\n",
    "    doc = re.sub(punctuation, ' ', doc)\n",
    "    \n",
    "    return [w for w in doc.split() if len(w) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. For example, the following code will display the first tweet stored in the variable ***k1_tweets_filtered*** (for the first keyword) before and after it has been pre-processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @TheoHarrison9: Oh please, now slimy shorten is hinting the High Court moved the goal posts.\n",
      "Trouble is,even if they did, Ludlum startin…\n",
      "theoharrison9 please now slimy shorten hinting the high court moved the goal posts trouble even they did ludlum startin\n"
     ]
    }
   ],
   "source": [
    "tweet_k1 = k1_tweets_filtered[0]['text']\n",
    "tweet_k1_processed = pre_process(tweet_k1)\n",
    "\n",
    "print(tweet_k1)\n",
    "# tweet_k1_processed is now a list of words. \n",
    "# We use ' '.join() method to join the list to a string.\n",
    "print(' '.join(tweet_k1_processed))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = []\n",
    "for k in k1_tweets_filtered:\n",
    "    w1.append(pre_process(k['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.7**. Use the example above, write your code to display the **first** tweets stored in the variables ***k2_tweets_filtered*** and ***k2_tweets_filtered*** before and after they have been pre-processed using the function ***pre_process()*** supplied earlier.\n",
    "\n",
    "[**Total mark: 4**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Cameron_Kirby plenty of share ones in Melbourne to practice on. It's like riding a bike. An acoustic motorbike.\n",
      "New Atlas (nee Gizmag)... Vintage e-bike gets black-out looks and adventure-ready performance… https://t.co/cdClGWqAZk\n",
      "RT @curatorofkitsch: Checked out the #WW1 German ersatz (substitute) bike tyres while in one of the @AWMemorial collection stores today. Ru…\n",
      "RT @CarCarLaJenkins: My son is shocked and devastated, his new bike we picked up yesterday for him to do the great vic bike ride is damaged…\n",
      "RT @JoinTheDrive: The faster you go, the harder you hit. When you’re on your bike, you don’t have the same protection as a car, so you’ll a…\n",
      "\n",
      "[['cameron', 'kirby', 'plenty', 'share', 'ones', 'melbourne', 'practice', 'like', 'riding', 'bike', 'acoustic', 'motorbike'], ['new', 'atlas', 'nee', 'gizmag', 'vintage', 'bike', 'gets', 'black', 'out', 'looks', 'and', 'adventure', 'ready', 'performance', 'url'], ['curatorofkitsch', 'checked', 'out', 'the', 'ww1', 'german', 'ersatz', 'substitute', 'bike', 'tyres', 'while', 'one', 'the', 'awmemorial', 'collection', 'stores', 'today'], ['carcarlajenkins', 'son', 'shocked', 'and', 'devastated', 'his', 'new', 'bike', 'picked', 'yesterday', 'for', 'him', 'the', 'great', 'vic', 'bike', 'ride', 'damaged'], ['jointhedrive', 'the', 'faster', 'you', 'the', 'harder', 'you', 'hit', 'when', 'youre', 'your', 'bike', 'you', 'dont', 'have', 'the', 'same', 'protection', 'car', 'youll']]\n"
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    print(k2_tweets_filtered[k]['text'])\n",
    "print()\n",
    "\n",
    "k2_tweets_processed = []\n",
    "for i, k in enumerate(k2_tweets_filtered):\n",
    "    k2_tweets_processed.append(pre_process(k['text']))\n",
    "\n",
    "print(k2_tweets_processed[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Cameron_Kirby plenty of share ones in Melbourne to practice on. It's like riding a bike. An acoustic motorbike.\n",
      "New Atlas (nee Gizmag)... Vintage e-bike gets black-out looks and adventure-ready performance… https://t.co/cdClGWqAZk\n",
      "RT @curatorofkitsch: Checked out the #WW1 German ersatz (substitute) bike tyres while in one of the @AWMemorial collection stores today. Ru…\n",
      "RT @CarCarLaJenkins: My son is shocked and devastated, his new bike we picked up yesterday for him to do the great vic bike ride is damaged…\n",
      "RT @JoinTheDrive: The faster you go, the harder you hit. When you’re on your bike, you don’t have the same protection as a car, so you’ll a…\n",
      "\n",
      "[['cameron', 'kirby', 'plenty', 'share', 'ones', 'melbourne', 'practice', 'like', 'riding', 'bike', 'acoustic', 'motorbike'], ['new', 'atlas', 'nee', 'gizmag', 'vintage', 'bike', 'gets', 'black', 'out', 'looks', 'and', 'adventure', 'ready', 'performance', 'url'], ['curatorofkitsch', 'checked', 'out', 'the', 'ww1', 'german', 'ersatz', 'substitute', 'bike', 'tyres', 'while', 'one', 'the', 'awmemorial', 'collection', 'stores', 'today'], ['carcarlajenkins', 'son', 'shocked', 'and', 'devastated', 'his', 'new', 'bike', 'picked', 'yesterday', 'for', 'him', 'the', 'great', 'vic', 'bike', 'ride', 'damaged'], ['jointhedrive', 'the', 'faster', 'you', 'the', 'harder', 'you', 'hit', 'when', 'youre', 'your', 'bike', 'you', 'dont', 'have', 'the', 'same', 'protection', 'car', 'youll']]\n",
      "\n",
      "@ElliotLangerman A good point, although I found non-fiction books were slightly better than fiction as audio books.\n",
      "RT @CHepworthAuthor: The Last Oracle: A Climate Fiction Thriller \n",
      "Click Here! https://t.co/AHsIp7CruP\n",
      "#climatefiction #sciencefiction #susp…\n",
      "RT @LamaJabr: The Last Oracle: A Climate Fiction Thriller by @CHepworthAuthor\n",
      "Click Here! https://t.co/U9FycxnSwa\n",
      "#climatefiction #sciencef…\n",
      "Truth is Stranger Than Fiction\n",
      "Source : Neet Onna to Shougaku 2-nensei https://t.co/3o1qp34G9N\n",
      "RT @LamaJabr: The Last Oracle: A Climate Fiction Thriller by @CHepworthAuthor\n",
      "Click Here! https://t.co/U9FycxnSwa\n",
      "#climatefiction #sciencef…\n",
      "\n",
      "[['elliotlangerman', 'good', 'point', 'although', 'found', 'non', 'fiction', 'books', 'were', 'slightly', 'better', 'than', 'fiction', 'audio', 'books'], ['chepworthauthor', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'click', 'here', 'url', 'climatefiction', 'sciencefiction', 'susp'], ['lamajabr', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'chepworthauthor', 'click', 'here', 'url', 'climatefiction', 'sciencef'], ['truth', 'stranger', 'than', 'fiction', 'source', 'neet', 'onna', 'shougaku', 'nensei', 'url'], ['lamajabr', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'chepworthauthor', 'click', 'here', 'url', 'climatefiction', 'sciencef']]\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Use the example above, write your code to display the first tweets stored in \n",
    "the variables k2_tweets_filtered and k3_tweets_filtered before and after they \n",
    "have been pre-processed using the function pre_process() supplied earlier.\n",
    "'''\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "for k in range(5):\n",
    "    print(k2_tweets_filtered[k]['text'])\n",
    "print()\n",
    "\n",
    "k2_tweets_processed = []\n",
    "for i, k in enumerate(k2_tweets_filtered):\n",
    "    k2_tweets_processed.append(pre_process(k['text']))\n",
    "\n",
    "print(k2_tweets_processed[0:5])\n",
    "print()\n",
    "\n",
    "for k in range(5):\n",
    "    print(k3_tweets_filtered[k]['text'])\n",
    "print()\n",
    "\n",
    "k3_tweets_processed = []\n",
    "for i, k in enumerate(k3_tweets_filtered):\n",
    "    k3_tweets_processed.append(pre_process(k['text']))\n",
    "\n",
    "print(k3_tweets_processed[0:5])\n",
    "#ds2 = []\n",
    "#for c, i in enumerate(k2_tweets_filtered):\n",
    "#    print(c, i['text'])\n",
    "#    ds2.append(i)\n",
    "\n",
    "#k2_tweets_processed = []\n",
    "#for i in (ds2):\n",
    "#    k2_tweets_processed.append(pre_process(i['text']))\n",
    "\n",
    "#print(k2_tweets_processed)\n",
    "\n",
    "#ds3= []\n",
    "#for c, i in enumerate(k3_tweets_filtered):\n",
    "#    print(c, i['text'])\n",
    "#    ds3.append(i)\n",
    "\n",
    "#k3_tweets_processed = []\n",
    "#for i in (ds3):\n",
    "#    k3_tweets_processed.append(pre_process(i['text']))\n",
    "    \n",
    "#print(k3_tweets_processed)\n",
    "\n",
    "#ds2 = []\n",
    "#for c, i in enumerate(k2_tweets_filtered):\n",
    "#    ds2.append(i['text'])\n",
    "\n",
    "#k2_tweets_processed = pre_process(''.join(ds2))\n",
    "#print('  '.join(k2_tweets_processed))\n",
    "\n",
    "#ds3 = []\n",
    "#for c, i in enumerate(k3_tweets_filtered):\n",
    "#    ds3.append(i['text'])\n",
    "\n",
    "#k3_tweets_processed = pre_process(''.join(ds3))\n",
    "#print('  '.join(k3_tweets_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.8**. Write your code to pre-process and clean up all tweets stored in the variable ***k1_tweets_filtered***, ***k2_tweets_filtered*** and ***k3_tweets_filtered*** using the function ***pre_process()*** to result in new variables ***k1_tweets_processed***, ***k2_tweets_processed*** and ***k3_tweets_processed***.\n",
    "\n",
    "[**Total mark: 6**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @TheoHarrison9: Oh please, now slimy shorten is hinting the High Court moved the goal posts.\n",
      "Trouble is,even if they did, Ludlum startin…\n",
      "@HarfSerious You are getting ahead of yourself and you haven't even coached a game yet\n",
      "#bigshorts #bigego\n",
      "@Nboyz98 @madmuzz_196 @bbcmusic @DUALIPA Muzz you better order your lfc shirt in time for the game\n",
      "@AKRacingAus You guys have actually made it possible for me to play a game for longer than 20 minutes! And for that I thank you 💜\n",
      "RT @kloud_kat: @flyingpig32 @RicepirateMick Honestly, one of the best uses of Heaven's Door I've ever seen.\n",
      "\n",
      "[['theoharrison9', 'please', 'now', 'slimy', 'shorten', 'hinting', 'the', 'high', 'court', 'moved', 'the', 'goal', 'posts', 'trouble', 'even', 'they', 'did', 'ludlum', 'startin'], ['harfserious', 'you', 'are', 'getting', 'ahead', 'yourself', 'and', 'you', 'haven', 'even', 'coached', 'game', 'yet', 'bigshorts', 'bigego'], ['nboyz98', 'madmuzz', '196', 'bbcmusic', 'dualipa', 'muzz', 'you', 'better', 'order', 'your', 'lfc', 'shirt', 'time', 'for', 'the', 'game'], ['akracingaus', 'you', 'guys', 'have', 'actually', 'made', 'possible', 'for', 'play', 'game', 'for', 'longer', 'than', 'minutes', 'and', 'for', 'that', 'thank', 'you'], ['kloud', 'kat', 'flyingpig32', 'ricepiratemick', 'honestly', 'one', 'the', 'best', 'uses', 'heaven', 'door', 'ever', 'seen']]\n",
      "\n",
      "@Cameron_Kirby plenty of share ones in Melbourne to practice on. It's like riding a bike. An acoustic motorbike.\n",
      "New Atlas (nee Gizmag)... Vintage e-bike gets black-out looks and adventure-ready performance… https://t.co/cdClGWqAZk\n",
      "RT @curatorofkitsch: Checked out the #WW1 German ersatz (substitute) bike tyres while in one of the @AWMemorial collection stores today. Ru…\n",
      "RT @CarCarLaJenkins: My son is shocked and devastated, his new bike we picked up yesterday for him to do the great vic bike ride is damaged…\n",
      "RT @JoinTheDrive: The faster you go, the harder you hit. When you’re on your bike, you don’t have the same protection as a car, so you’ll a…\n",
      "\n",
      "[['cameron', 'kirby', 'plenty', 'share', 'ones', 'melbourne', 'practice', 'like', 'riding', 'bike', 'acoustic', 'motorbike'], ['new', 'atlas', 'nee', 'gizmag', 'vintage', 'bike', 'gets', 'black', 'out', 'looks', 'and', 'adventure', 'ready', 'performance', 'url'], ['curatorofkitsch', 'checked', 'out', 'the', 'ww1', 'german', 'ersatz', 'substitute', 'bike', 'tyres', 'while', 'one', 'the', 'awmemorial', 'collection', 'stores', 'today'], ['carcarlajenkins', 'son', 'shocked', 'and', 'devastated', 'his', 'new', 'bike', 'picked', 'yesterday', 'for', 'him', 'the', 'great', 'vic', 'bike', 'ride', 'damaged'], ['jointhedrive', 'the', 'faster', 'you', 'the', 'harder', 'you', 'hit', 'when', 'youre', 'your', 'bike', 'you', 'dont', 'have', 'the', 'same', 'protection', 'car', 'youll']]\n",
      "\n",
      "@ElliotLangerman A good point, although I found non-fiction books were slightly better than fiction as audio books.\n",
      "RT @CHepworthAuthor: The Last Oracle: A Climate Fiction Thriller \n",
      "Click Here! https://t.co/AHsIp7CruP\n",
      "#climatefiction #sciencefiction #susp…\n",
      "RT @LamaJabr: The Last Oracle: A Climate Fiction Thriller by @CHepworthAuthor\n",
      "Click Here! https://t.co/U9FycxnSwa\n",
      "#climatefiction #sciencef…\n",
      "Truth is Stranger Than Fiction\n",
      "Source : Neet Onna to Shougaku 2-nensei https://t.co/3o1qp34G9N\n",
      "RT @LamaJabr: The Last Oracle: A Climate Fiction Thriller by @CHepworthAuthor\n",
      "Click Here! https://t.co/U9FycxnSwa\n",
      "#climatefiction #sciencef…\n",
      "\n",
      "[['elliotlangerman', 'good', 'point', 'although', 'found', 'non', 'fiction', 'books', 'were', 'slightly', 'better', 'than', 'fiction', 'audio', 'books'], ['chepworthauthor', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'click', 'here', 'url', 'climatefiction', 'sciencefiction', 'susp'], ['lamajabr', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'chepworthauthor', 'click', 'here', 'url', 'climatefiction', 'sciencef'], ['truth', 'stranger', 'than', 'fiction', 'source', 'neet', 'onna', 'shougaku', 'nensei', 'url'], ['lamajabr', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'chepworthauthor', 'click', 'here', 'url', 'climatefiction', 'sciencef']]\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your code to pre-process and clean up all tweets \n",
    "stored in the variable k1_tweets_filtered, k2_tweets_filtered and k3_tweets_filtered using the \n",
    "function pre_process() to result in new variables k1_tweets_processed, k2_tweets_processed \n",
    "and k3_tweets_processed.\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n",
    "for k in range(5):\n",
    "    print(k1_tweets_filtered[k]['text'])\n",
    "print()\n",
    "\n",
    "k1_tweets_processed = []\n",
    "for i, k in enumerate(k1_tweets_filtered):\n",
    "    k1_tweets_processed.append(pre_process(k['text']))\n",
    "\n",
    "print(k1_tweets_processed[0:5])\n",
    "print()\n",
    "\n",
    "for k in range(5):\n",
    "    print(k2_tweets_filtered[k]['text'])\n",
    "print()\n",
    "\n",
    "k2_tweets_processed = []\n",
    "for i, k in enumerate(k2_tweets_filtered):\n",
    "    k2_tweets_processed.append(pre_process(k['text']))\n",
    "\n",
    "print(k2_tweets_processed[0:5])\n",
    "print()\n",
    "\n",
    "for k in range(5):\n",
    "    print(k3_tweets_filtered[k]['text'])\n",
    "print()\n",
    "\n",
    "k3_tweets_processed = []\n",
    "for i, k in enumerate(k3_tweets_filtered):\n",
    "    k3_tweets_processed.append(pre_process(k['text']))\n",
    "\n",
    "print(k3_tweets_processed[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ds = []\n",
    "#for c, i in enumerate(k1_tweets_filtered):\n",
    "#    print(c, i['text'])\n",
    "#    ds.append(i)\n",
    "\n",
    "#k1_tweets_processed = []\n",
    "#for i in (ds):\n",
    "#    k1_tweets_processed.append(pre_process(i['text']))\n",
    "\n",
    "#print(k1_tweets_processed)\n",
    "\n",
    "\n",
    "#ds2 = []\n",
    "#for c, i in enumerate(k2_tweets_filtered):\n",
    "#    print(c, i['text'])\n",
    "#    ds2.append(i)\n",
    "\n",
    "#k2_tweets_processed = []\n",
    "#for i in (ds2):\n",
    " #   k2_tweets_processed.append(pre_process(i['text']))\n",
    "\n",
    "#print(k2_tweets_processed)\n",
    "\n",
    "#ds3= []\n",
    "#for c, i in enumerate(k3_tweets_filtered):\n",
    "#    print(c, i['text'])\n",
    "#    ds3.append(i)\n",
    "\n",
    "#k3_tweets_processed = []\n",
    "#for i in (ds3):\n",
    "#    k3_tweets_processed.append(pre_process(i['text']))\n",
    "    \n",
    "#print(k3_tweets_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.9**. Now, write your code to print out the **first 5 processed tweets** for each keyword *(the processed tweets are stored in **k1_tweets_processed**, **k2_tweets_processed** and **k3_tweets_processed**)*\n",
    "\n",
    "[**Total mark: 7**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 processed tweets for k1_tweets_processed:\n",
      "[['theoharrison9', 'please', 'now', 'slimy', 'shorten', 'hinting', 'the', 'high', 'court', 'moved', 'the', 'goal', 'posts', 'trouble', 'even', 'they', 'did', 'ludlum', 'startin'], ['harfserious', 'you', 'are', 'getting', 'ahead', 'yourself', 'and', 'you', 'haven', 'even', 'coached', 'game', 'yet', 'bigshorts', 'bigego'], ['nboyz98', 'madmuzz', '196', 'bbcmusic', 'dualipa', 'muzz', 'you', 'better', 'order', 'your', 'lfc', 'shirt', 'time', 'for', 'the', 'game'], ['akracingaus', 'you', 'guys', 'have', 'actually', 'made', 'possible', 'for', 'play', 'game', 'for', 'longer', 'than', 'minutes', 'and', 'for', 'that', 'thank', 'you'], ['kloud', 'kat', 'flyingpig32', 'ricepiratemick', 'honestly', 'one', 'the', 'best', 'uses', 'heaven', 'door', 'ever', 'seen']]\n",
      "\n",
      "The first 5 processed tweets for k2_tweets_processed:\n",
      "[['cameron', 'kirby', 'plenty', 'share', 'ones', 'melbourne', 'practice', 'like', 'riding', 'bike', 'acoustic', 'motorbike'], ['new', 'atlas', 'nee', 'gizmag', 'vintage', 'bike', 'gets', 'black', 'out', 'looks', 'and', 'adventure', 'ready', 'performance', 'url'], ['curatorofkitsch', 'checked', 'out', 'the', 'ww1', 'german', 'ersatz', 'substitute', 'bike', 'tyres', 'while', 'one', 'the', 'awmemorial', 'collection', 'stores', 'today'], ['carcarlajenkins', 'son', 'shocked', 'and', 'devastated', 'his', 'new', 'bike', 'picked', 'yesterday', 'for', 'him', 'the', 'great', 'vic', 'bike', 'ride', 'damaged'], ['jointhedrive', 'the', 'faster', 'you', 'the', 'harder', 'you', 'hit', 'when', 'youre', 'your', 'bike', 'you', 'dont', 'have', 'the', 'same', 'protection', 'car', 'youll']]\n",
      "\n",
      "The first 5 processed tweets for k3_tweets_processed:\n",
      "[['elliotlangerman', 'good', 'point', 'although', 'found', 'non', 'fiction', 'books', 'were', 'slightly', 'better', 'than', 'fiction', 'audio', 'books'], ['chepworthauthor', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'click', 'here', 'url', 'climatefiction', 'sciencefiction', 'susp'], ['lamajabr', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'chepworthauthor', 'click', 'here', 'url', 'climatefiction', 'sciencef'], ['truth', 'stranger', 'than', 'fiction', 'source', 'neet', 'onna', 'shougaku', 'nensei', 'url'], ['lamajabr', 'the', 'last', 'oracle', 'climate', 'fiction', 'thriller', 'chepworthauthor', 'click', 'here', 'url', 'climatefiction', 'sciencef']]\n"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Now write your code to print out the first 5 processed tweets for each keyword.\n",
    "Hint: Each tweet in tweets_processed is now a list of words, not a string. \n",
    "      To print a string, you might need to use ' '.join(tweet), \n",
    "      when tweet is a processed tweet\n",
    "\n",
    "'''\n",
    "\n",
    "print('The first 5 processed tweets for k1_tweets_processed:')\n",
    "# INSERT YOUR CODE HERE\n",
    "print(k1_tweets_processed[0:5])\n",
    "print('\\nThe first 5 processed tweets for k2_tweets_processed:')\n",
    "# INSERT YOUR CODE HERE\n",
    "print(k2_tweets_processed[0:5])\n",
    "print('\\nThe first 5 processed tweets for k3_tweets_processed:')\n",
    "# INSERT YOUR CODE HERE\n",
    "print(k3_tweets_processed[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. The following function ***construct_termdoc()*** has been implemented to construct the term-by-document matrix from a corpus of text data. **You will need this function for subsequent task**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_termdoc(docs, vocab=[]):\n",
    "    \"\"\"\n",
    "    Construct a term-by-document-matrix\n",
    "    \n",
    "    docs: corpus\n",
    "    vocab: pre-defined vocabulary\n",
    "           if not supplied it will be automatically induced from the data\n",
    "    \n",
    "    returns the term-by-document matrix and the vocabulary of the passed corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    # vocab is not passed\n",
    "    if vocab == []:\n",
    "        vocab = set()\n",
    "        termdoc_sparse = []\n",
    "\n",
    "        for doc in docs:       \n",
    "            # computes the frequencies of doc\n",
    "            doc_sparse = Counter(doc)    \n",
    "            termdoc_sparse.append(doc_sparse)\n",
    "            \n",
    "            # update the vocab\n",
    "            vocab.update(doc_sparse.keys())  \n",
    "\n",
    "        vocab = list(vocab)\n",
    "        vocab.sort()\n",
    "    \n",
    "    else:\n",
    "        termdoc_sparse = []        \n",
    "        for doc in docs:\n",
    "            termdoc_sparse.append(Counter(doc))\n",
    "            \n",
    "\n",
    "    n_docs = len(docs)\n",
    "    n_vocab = len(vocab)\n",
    "    termdoc_dense = np.zeros((n_docs, n_vocab), dtype=int)\n",
    "\n",
    "    for j, doc_sparse in enumerate(termdoc_sparse):\n",
    "        for term, freq in doc_sparse.items():\n",
    "            try:\n",
    "                termdoc_dense[j, vocab.index(term)] = freq\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return termdoc_dense, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. Now suppose that we would like to construct a term-by-document matrix for tweets collected for the **first keyword only**. The following piece of codes will do this by computing the term-by-document matrix and the vocabulary for tweets stored in **k1_tweets_processed**, print them out and visualise the corresponding term-by-document matrix stored in the variable ***k1_termdoc***. The corresponding vocabulary dictionary computed from this data will also be stored in the variable ***k1_vocab***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "&amp 1060 2000s 250th 278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Term-by-Document matrix from tweets collected for keyword \"game\"')"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAFNCAYAAABylXoZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnXkYXUV58H8vJCyyhCWsCRI00aoVAaOCWESoFqmF+LlXK1I1WmnVYlX8tKJt/VRsBbVuERS0VlBUoIooOy4sJoogIiUiksiSsEUWxQTe74+ZSw43dznLzJmZc+b3PPe59571nZl35p31HVFVMplMJpPpGhuFFiCTyWQyGR9kA5fJZDKZTpINXCaTyWQ6STZwmUwmk+kk2cBlMplMppNkA5fJZDKZTtIZAycim4mIisjc0LJkmiEivxKR/Wrct5GIfFlE7haRS3zIlgEROURElhf+3yoiz4pJphHnD7R6da+IHOLgfaeKyHuaPicUInKZiLwqtBy+qW3grKIMPg+JyO8L/1/pUsgQ2Ex7v4jcIyJ3icj3ReR1IiKhZXOFiHxIRE5s8X2lCgVVfayqXlrjFQcD+wG7qOoBNe5vhIi8UUTOa/mdnajYtWAwPgAcp6pbquo5Ht+TPLZcOMZWGqKLK2uc9x3IOena2gbOKsqWqrolcBPwV4VjX64o8Iy6cnjmeaq6FbAHcDzwXuBTYUXqLg70YHfgBlX9vafnZ9Jld+CaOjemrDcpy+4EVW38AW4E/nzo2MbAPwM3ALcDXwa2sef+BFgHvB5YAXyvcOy1wG+BO4C/xdTIfw7cDXx0ggybAQr8vZVnNabWJsCjgN8BCwrXzwXuH8g04nm3As8aOvZnwEOD5wDbAf9t3/Vr4B2AFK5/E/BL4B7gauDJBTnnFq47FXiP/X0IsBx4j4233wKHAocDv7Lx8raK8XwksNLK+XZ7bhHwR2AtcC9wxYR4OBpTONwLfBrYBTjXxuk5wNb22hnA14HbbHpdCDzennuzfdcD9jlfKzz/n+zz7y/GvU2784EPFOQ5A/jUCDnfBPzBhvde4P8W4vKfrUyfs9ceVYjLbwA7DenQG+3539l0eDxwBbDGxu+MEe/fe+j9twJPAFYVrvkv4KbC/9OBNxZ06Yv2vhXAscBGhWvfAFwH3Al8G5hjj19hZb7PvncRsLNNl7ttGC+YkG+eAlwA3GXf/TZ7fHPgk8AtVnc+Asws6uiovMIEfbTnDwQus3F5E/DXE3RjN+BM+5wbBnFlz21hn303Jm+9qyjTUBhXYvLt/cC99tijgbNtfP4vcETh+g9h8vVpmLz7qhHPLObZWcAPgI8U4u4Em463Ap8ANrXnlgPPHSq31lhdOQ04yh6fb9P1b+3/PwVuLdw3TYf/zp7/pT3+l8D1Nr4+atNgg3AVwn+MTedzCseLzzih+AxMWXORjc/VwCnAVnXKkUJZe7l910+A/QvnLgP2Hcg50TZNM15lPow2cMcA3wd2tZF+MvCFQmQocCLG+GxeOPYxYFPgMEym/TqwvVXIu4BnjJFhkLDfBbbBtLpuKCTA54H3F65/JzYjTSjYnzXi+CrgSPv7q8DXgC2tQv4aeKU99zfAbzAFn2AKybmUM3BrrXwzgH+wsnwJk6kHBemcCvH8SXvuaRij9piCIp84JW1vtc+fXUiDKzDGenNMxn6nvXYGcISNj80wSnzZqHAOPf/HVv7NRxSYu2EKuP0xlZ/rgEeNkfWNwHmF/4dgDM6/AJtYeQ+1z9/TyrgEOHdIhwZpurdNi+9hWgDbYTL4y8q83x67DXiS/f1r+9mjcO4J9vd3MAXhozAZ/6fYQhd4OXAt8DhgJvBvwIVDMhf16XhMPpphw33AGHm3xRRGf4/Jc1sDT7Pnjiuk+042jd5diNdxBm6SPs7HFG4vsrLtADxllG5gDOXVmHywiQ37TcCz7fkTMJWfQV6/jjEGblR+xhSex9twL8QUzPsX8sUDVlc2wurl0PNOxVR+drRpVZT9M5jKyzYY4/dd4Fh77r3AKYVrXwb82P5+E+uN+99iDNQphXOn2d9ldPjb9v2bYyo892HK1JmYysA6xhi4MfG3s027F9hnvAOTN4oG7iCbVjtjjNCHapYj8zCG+89t/B+K0dNty8r78Hur3jAm8DeyoYH7NY+0untgalDC+oJ318L5wbHtC8fuAw4v/P82hVrc0PsGCXtg4djRwLft72fzyEx5NXBY2QxROH4l8DZMxngQayzsubdgazzAxcAbJsg5ycCtwdbeMYWAYgsCe+wa4JAK8Ty7cP4qYFEhI5cxcC8aSoPjC//fDpw6IVM8BGw2HM6h5//1pLgHXml17E7g6RNkHWXg7sO2POyxLwP/Uvi/jZVx50LaPHUort9S+P9JChl30vvtsa9hCqd5Nu4/DrwGU2O/zV6z+wg5jwS+Y39fiK042f8zMYXLTmP06Tj73seMi6vCOy4dc+63wEGF/4ezvjUwycBN0sf3A18Z875hA/ds4Pqha94PfNr+vplH5vU3U9LAAQswlcTNC+ePBz5TyBffmxJ3pwKfxVQ83lw4PgNTiZxTOPYc4Fr7ex4mfz/K/v/W4H7gSQWdOBnTw/Vr+/804E0VdPiZhfOLgYsK/zfGVNSrGLjF2EqV/b/RpGdgKmWXFv6XLkcwvRefG3rexYypWE76eJlFaSdi7AacbWe03Y2p5WyEaY0BPKSqNw/d+qCq3lH4/3tMLbf4f0v7jsGMqHtF5GmFa1YUfv8GU5MEuATYWET2E5G9MLXk79hnXVB41oumBG8OpqDd2YbnpqH3zbG/d8PUwOqwWlUfsr8H40kbxEPJeH5QVW8v3Hs/Ng4rMPzucWkyQ0T+XURuEJHfYbpnpSDLOFZMOf8NTOv1p6p6RSXJTbfO2sL/XTHpBICq3o3pIplTuKZUeEtyMaZb7gD7+yJM4f1sjE6CMXCbAasL6fgxjAEbnP9M4dxqTA183MSSD2AMwIUislxEjh5z3UgdtXq1M4V44pG6PZIS+lglT+wOzBs8xz7raGBn+56d2DCvl2VXTB4rjtUOh2+aToLpDgY4aejZM4FrCnKfgWnpoao3YuLkcBHZAdPqOdXe+wtgIxF5IqaL/pvAPSKyO+v1Z/COaTpclH/X4n9VfRBTganC8DMeKj5DRHYVka+JyG9t3j8R01orUjZf7Q68aijtF7K+LC+NFwOnxuQOaoDbFD6bFQpbbfiOx+r6SS0/LpzarfD70ZiMPpDpi8CrMN2Hpw4KPlU9qPCsr497p50KvT2mOX0rptb06KH3DRJ9BfDYEY8ZjHs9qnBs52nhHUXJeJ74iDrvncCRwPMwNdZZmBYkGCM36X3T5DgOWAY8TkReWFGm4WffjMlARjCRWZiuuaoZvsy7wBRKz2Z9AXWJ/f1s1hdYKzDdP9sW0nBrVd2ncP41Q2m8uaouG/VOVV2jqm9R1d0x3YHvEZH9R8g2UketXt1KIZ54pG6PDvx0fRyXJxgRjhWYFmPxOVup6gvte1axYV4vy83ADiKy+YTwlckb/wn8CPifwrNuwVQ+HluQe5aqFit5p2DKoZdjxkdXwcPxdwmmx+IPNs4uxoy/zsAYwIH803S4KP8tFOJKRDZiSmVlBLdQqFCNeMZHML0Qf6qqWwOvY32+r8oKTM9SMe23UNXjqz7I5zq4zwAfEpHdAERkRxH5K4/vG/BOEZklIvMwYwunFc59EXgp8Ar7uxT2eYswkwROVNXrVfUBTA3r/4nIFiLyWEwX5X/Z204EjhGRp4jhcSIy19Z8rgZeKSIb2zipvOarQJN4vg3Yw+HSh60wXT93YFpc/zbifY+p8kAReS4mzY7AdO19RkR2mnjTZL4CvF5E/lRENgM+jClkbm3wzAG3AbuJyMzCsZ9juoReAlxiC637MQP2FwOo6q8xYxbHichWYtbzLZD1a8s+gzFSjwcQkW0HPQ1WD9dQiFcROUxEBum6BtOV/uAIec8A5ovI34nIJiKydaE35CvAsSKyvYjsCLyb9bo9iUn6+EXgBSLyQqv7O4jInoW4K+rGD+z9bxWzFGKGiOwpIgOj/1Xg3TZv7o7pBi7Lckx38b+JyKb2mUdguv6qoJhuxN8CZ4jIprbS/HngYyIy2+b93aweDzgd00L7OzYshy7GjLsPKj8XYcqxS6wBhOo6fBbwNBF5gdXNt2PGk6twFvAMETlUzMzMozFjuAO2wlTSficij7bn63IK8BIROdjqyeb2d+WGgE8DdxxwHnCBiNyDqensM/kWJ3wb+BmwFDMO8XCmVNVfYQaj7ynZ1fU9EbkX0x3wduCDmHGWAW+w37/BzEQ7EZtJVPVLmNlKp2O6DwaDzmAU9mWYgdYXYvrh69Iknk/FtCTvFJEfNZBhwEmY7rNbMUb8B0Pnl2Ay2t0icurwzcOIyLbAFzBjmbep6vlW5s/VFVBVv4VJx7MwNeGdMS16F5yDGStcJSIr7fsUM7h+86Cmjim81mKM34BXYPTjl5gu8NOwXZSq+hVMa+EbtvvnSqBYYL4X+JqN18Mw43sXYWYAXgL8u6peNiysqt5ln/NyTIvoOkzBO3jmLzBjkFcCP8To2jTG6qPNf4djZrjehcmjT7L3PUI3rKE4FHgmJn+txkxaGnRjDWYZ34TJ86UrrDZNXgo8EaOrp2FmF3+/7DMKz3oIU/G6G/i6iGwCvBWjW0sxFYxzMBNsBvfcA/wPpgV01tAjL8YYi0H39SWYMF9SuL+SDqvqLZg0PgETjztZ2aqE8xaMjn4cE+9zMXn8AXvJezG6swZT8R/bE1biXTdgeh7eb9/1G0zjobK9kvWVgn4gIv8N/EJVh1sXmUwm0woi8v+AHVX1daFlqYNtxd2KWf9cxylDK3TGVVcZRGQ+ZprrF0LLkslk+omdXPIaTKs1GUTk+bZLeDPMTMf7MWPj0RKVgRPjGuY6MTO/JrpgqfHs4zCzl/5FVV1MKMhkMplKiMjAEcXXaswIDs0BmGUgqzBu8V6oqn8MK9JkoumiFJGNMR4FnovxPPBj4BWq+ouJN2YymUwmM4KYWnBPxyzUvMHWCk7FDEhnMplMJlOZmAzcHB65OHEl1ddqZDKZTCYDmMWDsTBqLdYG/acishjjNoaN2fipj2Jr33I1Yt3sLZhx+32hxQhGCuFPQUYXuA5nleeFjOMy7552zbTzDy7YlI2vf2DseZ+EjNt7uOt2Vd0hyMtLEJOBW8kjPRPMxXohKaKqS7Czj7aW7fQZcnA70tXlDuqv5+8At79oP2YvqTaL+PbF1e9pRF/SyHU4qzwvZByXefe0a6adX17iHb4IGLfn6elVXKS1TkxdlD8GFlgPDJtgFiYOL4LMBOD2xU0crVTHl3FrOxwxkuOgO6w5e/70i0rSVb2IxsCp6jqMh4/vYjx0f1VVJ25QuG72Fm2IFgUhFbCuwYkt07TaKoyUNuMgtvTvGmvPcNczWKeXJQWiMXAAqnq2qj7OOlL+wLTrx/U7u4r8Ms9pK6GrKGAsytdVgxJL/MZOiPQPlTaT3nv74v2cyjV4VjF+u9LL4ppo1sHVYdwYXOtjOB1iVObJtE/W4WqkEF+u81YMYT5PT1+mqguDCjGBThq4TDiGM10MmTAksYQ/V1wyPojdwEXVRRkjXeqOaiMsXS9Aq8ZhLGNes5dc2vm0CUlXygnX3amhSdrAtTHJxEehEEqBxoWlSwrtm1gM1iiyAQtHV8Ybu1YRStrANV3cOG1guO6904hNgZrKk7qBjGkyURFfs1dTT682qBpHOU7jJGkD55NphUtsRqpLjCosfBYgZdIy1vQeFS9t627Zbq22jICL97SV3l2qKMdIrwxcm8sH+kSZjFYlzkY9L2fm0bQdL+MMakyVhJR0pcmwQS6HptMrAzesTHUzQopr0kITc6HTlzRy3bKp8ryQcezCWEw7P3PR6koyTaNKhaEv+luHXhm4MrhWlpgL9owhp5HB56SWkHHsonU57fysQ5c//LvtmYgu4jaVykpVem3g6oxfTLo3459x8V4nPVJNw7pyVynEXfo57DJNumx9vLsuqVRWqtJrA9ckoVJK5C4xLt5HHZ9WAKSahm3IXWyRjCN0BSH0+yGsDs1ctDqKOIiZXhu4UMsEukasceGyNR5rGEfRlu6GriD4fH8KywTWnrFD8DSIneyqK+OVWFxVDROrXJluk5oru2nyZVddmc6RUmtmHE0KFZfjgJn+0tS4tTHuHLPxLUM2cJnKpK704yib+auMA2bGE1uFoIk8g3urjPuG0Je+6Wg2cB2haqsitsIlBqYtug0RZ11OJ5fbxri4z8WkszYNSN+MVR06beD6NHW8aqsiRq8SsQ7sVy28Qk3f7it1ZtCOu883sZQvscjhm04buGkK3GQdXB36olR1mb3k0sYuvWIgVrn6RAwuzEZd41Ku7MdyOp01cDEak5BKFSo+XAxqu5A9Rn0IQY4HP8TkizOzns4auFgULpYCJeXM5UL2Sc+IJY18E7IF0XVflCE8v2RflNPJ6+A6QqzraXzKFWuYM/1jzdnzS3l/CYHPfJLXwWVaoYsFfa6ZZrpGShvndoFs4DLRkjedHU82/nGx9owdSl0XyySTlN9dhWzgMpkESd24DxeQfSmsU19CMpA/Ff3rtYFLpRbik5TjIGXZQxM67lxtPuwCX5OY2l6G5IpJupGC/EV6beBSSywfpBwHKcsempjjzrfx9fH8UbMoY47jSaQq9yh6beBC12IzmS7SNF/5LmB9PH/UDMpUy5dU5R5Frw3cgLIJGtO4QVdw4eA20wzX8dilFkATfMeDL/3vUvplA0e9/vO8Bms9oVwGtemsNyVjWnXRctbjDYnVL2qmGtnAjaHJFPWs7NOJyf1WLF5vXJGXVzSnahyVvb6Kx5PQnmJCeGdxTScNXNN9vao8J8aZUm0b2Drh9e1+yye5AhMvMfpcvX3xfg+fr+LtZNr2Tb71P1bPLFXopIFzsa3JtC7ImNeDxOhJPWaqVmRiTPMiTf0qpkzoPeZGMXvJpU51ZpQPyth1MhSdM3CutlvpWzdPnwesu9RFWWZsuG5YumwYh+lz70AMMriicwbO5wabseIiHL4me6QQx6l6shiFz4I5FSMfgrq9Rk0m/PhKj2nPTWlsrnMGrgpdybBdCUco2vQP2GZapVC56BsuPbiESt+yfjdjoJcGLmf8zDTq6khxV/LQeuZzPCp02Ab0xYelC9qcdRwLnTRwrmrRqa6PilGm1GjS7Tq4N6WCYBKjwhFL2IblaFP3h9fFjqM4i9IFoya4lXl+LGnWJp00cGULJxeGMMYB+z4qcpvk+I23EhVqPHjmotVjz8U2izLWtPNBJw3cJIqKkLoH8xjoU2bpA67WkMaIT5lDrBmbZFQnkWLa1aV3Bi7jlj5llj6Q0zMdykz28FUBTaVi20kDNy7yU0kU3+R4KEeOp3C4jvu6DtVdP98lZTwxhVpKEAuiqqFlqM3Wsp0+Qw4OLUY0hHIAPem92Sl1pg+sOXt+J1xbVeU8PX2Zqi4MLcc4vLXgROTzIrJKRH5eOLadiJwrItfb723tcRGRj4vIchG5SkT28SVXkWkzn+reG4psSOqR6mzZcaSou7FRNY5CrA3L6Tgdn12UJwOHDB07BjhfVRcA59v/AM8HFtjPYuDTHuXKZDKZTA/wZuBU9RLgzqHDhwOn2N+nAIsKx7+ohsuAbURkF1+yDajiizLvoTWemOKiTq22LV+UbY3vVPFFmVsBGzLoVo89bqouDYg9PD5oe5LJTqp6C4D93tEenwOsKFy30h7zTlmvEzEV4pnxxJxOdWVrw79kHwu/cfhaqB8yjl2vxUuFWGZRyohjI2e/iMhiEVkqIkvX8sDEh1ZZ3V818WN2XxSaqrXFHG8bksKefplqdC2OU8i3bRu42wZdj/Z7lT2+EtitcN1c4OZRD1DVJaq6UFUXzmTTiS9r27N61xS4LlVri6nGm88ux1TjpK80df+XgrEYJgUdbdvAnQUcYX8fAZxZOP5qO5tyX2DNoCvTJ12bRRmK1OOi7Z3bfRcMWXebUzWOmnqAqaMTOR2n420dnIh8BTgQmA3cBhwLnAF8FXg0cBPwElW9U0QE+E/MrMv7gSNVdem0d3RlHdzwWrEya8dCri9LfW1bDPKPWzfV1/VUVYgh/UIzyuFyCHq7Dk5VX6Gqu6jqTFWdq6onqeodqnqwqi6w33faa1VVj1LVx6rqk8sYNxf48PBdh3F7RE16ZqgF3aPenVpNMnShAON9F3bduE3b8LMMMaTfMHU3AW2yLZNLUsvDZYllkkl0VO3m8ZHpYsvIXe1GyQu928Plhp8+aWuhdyzhj0UO12QDN4Yqa4naxGfh5Ls2GauRaGsdXFvEoLu+fUn61qVY0zvWPBQrvTZwbSmxS6UsMzbn69lN8fH8GDP8qMI4FjnbkqNMWleRpUzLL6aW6TiayhiD4Y1Fl8vQawPX1izKNpUy5NhcCNryMNK0MG4zXaaN3cZSQLmOE5fPa3sWZUqkFIZeG7hMJpPJdJdeG7gqviirnoe0mvJlcbkeLBbyGJwbYtZ31/48R10fc/j7Sq8NnG9SKhTL0sUwZdwQs25M2q+wCuOuX3P2/Mbh922EXbwzNXpt4LInEzekHhd5mUB/qWr4xl3vYj84F/5wfb8zNXpt4Hx3UfaF1GuSdbooYzYSTXU35rC1RZ0uyj6Rio702sCVxUVidq2V4JrUxjS7XKB1KWxt7cFX15NJE2YuWl36Wtd5JxUd6bSBc5WoLhIzRt+SMRmMMhRdmKUmeyYMbTnEDuFirUq3aCoGyTWdNnA+u2JcFbAhnaa28U4fXXvT1pVl47eeHBfxkUKapCBjGTpt4Hziyjh0vWbV1GdnV5zxhqJrcdG04K1zv29HAHVlaHu/yxTptYHrSiJ2mVS8pnelxluGYljbCHfxHU31oc79Ze6pMh5Wh9hck6VCrw2cD7LSPZLYKhGjFuSmNN3aZbe6C+faIbq5YyTEGNzwHpKZDckGzjFttDgGx1JQ6hhlTGXLllE0kTXlcGc2xGXLtsm7Y6ZXBq7tLTfqUGbManAs1QLK91YqoZ4RK6l3y6aQNinIOIkQXlTaoFcGruysyiqJHcMAdMxMMtA+31GFEEs0Rskw6rcLyuwQ3+S5k0ip+9cHPg2fy3hJOY4n0SsDN8y4LpsqiR3j+raYSL1m2xZtj2u5oEza+jKuVXBRCZ12ftwkkxQ3l+0SoqqhZajN1rKdPkMODi1GZgJ1DHzfKwWZTCqcp6cvU9WFoeUYR69bcJlytF1D7ON2Lm2R46A7uHQP1lW9SNrArZu9RWgRWiN2Z8SjiC3T5FZhu3EQW/p3DRc7GAwIsZNBGyRt4Gbcft/I467daDW9xgVVFDAW5euqQYklfmMnRPqHSptpW2+5lGuUe7+u9LK4ppNjcHkMpz4hfWNm1pN1uBopxJfrvBVDmGMfg+ukgcuEYzjTxZAJQxJL+HPFJeOD2A1c0l2UbdCl7qg2wtL1AjTmBbGTZJu2A0OmGV0pJ7q2FVXSBq6NSSY+CoVQCjQuLF1SaN/EYrBGkQ1YOLoy3ti1ilDSBm7cJJOyTBsYrnvvNGJTIBeeQFImpslERXzNXk09vdqgahzlOI2TpA2cT6YVLrEZqS4xycG0D8qkZazpXWefMB8OwWOqJKTkHqxLFeUY6ZWBa3P5QJ9w7ZOwDf+VXSEGL/Jlu7XakjUlXWkybJDLoen0ysC52i4kxTVpoYm50OlLGrlu2bh2Su6LkL4o61KlwtAX/a1DrwxcGUJ4XM+EJaeRweeklpBx7KJ1Oe18ccPTtmciuojbVCorVZlq4ERkPxH5pIhcJSKrReQmETlbRI4SkVltCOmLOuMXk+7N+GdcvNdJj1TT0MVO3NPOu/Rz2GWadNn6eHddUqmsVGWigROR7wCvA74LHALsAjwReA+wGXCmiBzmW0hfuNwdOdMO4+J91PFpBUCqadiG3MUWyThCVxBCvx/C6tDMRaujiIOYmdaC+xtVfa2qnqWqN6vqOlW9V1V/oqr/oaoHAj9qQU4vhFom0DVijQuXrfFYwziKtnQ3dAXB5/tTWCaw9owdgqdB7JRy1SUiWwC/V9WHRORxwJ8A31HVtb4FnER21RU/sbiqGiZWuTLdJjVXdtPk64qrrkuAzURkDnA+cCRwsi+hMnGTUmtmHE0KFZfjgJn+0tS4tTHuHLPxLUNZAyeqej/wf4BPqOoLMWNxmR6SutKPo2zmrzIOmBlPbBWCJvIM7q0y7htCX/qmo6UNnIjsB7wS+LY9NsOPSJk6VG1VxFa4xMC0Rbch4qzL6eRy2xgX97mYdNamAembsapDWQP3FuBdwDdV9RoReQxwoT+x3NCnqeNVWxUxepWIdWC/auEVavp2X6kzg3bcfb6JpXyJRQ7flDVwO6nqYar6YQBVvQH4vj+x3DBNgZusg6tDX5SqLrOXXNrYpVcMxCpXn4jBhdmoa1zKlf1YTqesgXtXyWPREKMxCalUoeLDxaC2C9lj1IcQ5HjwQ0y+ODPrmbbQ+/ki8glgjoh8vPA5GVg35d7dRORCEblWRK4RkbfY49uJyLkicr393tYeF/vs5dZryj5NApYVzg0xFIguZpp1Ia1T8pKfycTAtBbczcBS4A/AssLnLOAvpty7Dnibqj4B2Bc4SkSeCBwDnK+qCzBLDo6x1z8fWGA/i4FPVw6NR2Io6JvQhmPpGHA5ccA1TSdDdGnz3ZipM6ko9v0Cu7ZTd1kmGjhV/ZmqngLMB74KXKaqp6jqN1T1rin33qKqP7G/7wGuBeYAhwOn2MtOARbZ34cDX1TDZcA2IrJL3YAVyTXf5tTN7G3HW8zpFGMlIzWfia7fO2kc3od/Rpd7HVYdr3bR/Z+akSw7BncIcCVwDoCI7CUiZ5V9iYjMA/YGLsdMWLkFjBEEdrSXzQFWFG5baY81ZtL079QSLBShnbHGmhFjLrxjIVSlo81hCpcTPorPKvtcXw64m14fmrIG7n3A04G7AVT1SmBemRtFZEvg68BbVfV3ky4dcWwDP2IislhElorI0rU8UEaEkQy8paeWYLHiu8ANlRFjddgcq9661IOUjHhZqhrdSTOLy14QAp4yAAAgAElEQVRXli6umS1r4Nap6pqqDxeRmRjj9mVV/YY9fNug69F+r7LHVwK7FW6fixkDfASqukRVF6rqwplsWlWkTCaTyfSEsgbu5yLy18DGIrLAzqycuIuAiAhwEnCtqn60cOos4Aj7+wjgzMLxV9vZlPsCawZdmT6YdejyaGvBKTLNC0iq9Hn39jrhcZmnupg/XcZpnQlVk95fxilEajpe1sD9A/Ak4AHgv4E1wFun3LM/8DfAQSJypf0cCnwIeK6IXA881/4HOBu4AVgOfA54U9lAtDFI64rUFKTrZK8j40m5YIuV0BWApu9PTcdLGThVvV9V3w0cqKpPU9X3qOofptzzA1UVVd1TVfeyn7NV9Q5VPVhVF9jvO+31qqpHqepjVfXJqrq0bCBCTGpoa1A3BVIu/MqOXaQURh+620W9nUQK6Z2CjKEpZeBE5Jki8gvMVH9E5Cki8imvkrXApEw7LUP3LcNPYhAXqWa4WJwCtLURadbd6aQ6u7Drs4erUraL8njMwu47wKyPAw7wJVRb5B293ZC6t5BYWnBtzfzMujudWJelTCNGJ+ohKWvgUNUVQ4cedCxLVLisBftU/hgyVpOWcCpMCsdwGoROk6624NqM16pxNHPRak+SZJpQ1sCtEJFnAioim4jIP2G7K1MilBsnnzXzGAqrJi3hNvC9lm34/hjSJCWabjQbA2vP2KHWfSnuCBBDni5LWQP3RuAojGeRlcBe9n8yuN6qIgSxyZ9K12RV+VLKwCHxMWaYSty3NV466Z2h4ir2/F6krIG7V1Vfqao7qeqOqvoqVb3Dq2SOSSlRXBGbd5FhYi3MUtSVUM5+Xb93ktuqmBiWc9n7qvmGdzGTtav5zyVVFnr/UEQ+JCKHisgsr1JlnOBimxnX1xaJxZCEzuguXCyF2G0c/O9yHouOFBkVlr/Yda9Kz3ARrqZpGWPcuqbsOrj5wCuAq4EXAD8TkSt9CpYSoQtIH4R2rtwmoeVvc/Ft9p3ZHF+b8qZEKuEtuw5uLsYzyZ9hdgW4BjjNo1zRUcfFTaZ9Ys54MXrciTm+QlFnP7gQhNwPLpUyr2wX5U0Y11zfUdX9VPUvVfWDHuVqhcGOAmVIJUHbouyWHl3ZDy7knoI+/XxOkyk2d3ZtrkesMsbY1A+kb8btB1eW2I39OER1gx1pNrxI5CnAszCLux8NXA9crKon+RVvMlvLdvoMOTikCJkpdGH2aiYD43U5dR2vKn/x+vP09GWqutCXbE0pOwb3M8zu218ALgCeDfyzR7kqk13UxEuOs9HE1vWY02kyZbztx0LV3b6rEGN4x1F2DG4pcCnwQuCXwAGqOs+jXJVJbdF2n6gTZ30obH3qUp0p/Hm9YFpMGmLJ5ZSh7Bjcm6yH/zeo6pdU9TcisodXyVoiZCYNPdbgiipjmWVJPYPGkH6+4zDlNAqVPi7zyjjvKTHoXiyUNXCfGXHsdJeC1KXsZIdxhMykbflw9D17b9ahy8eeS7kQbILrcLsotGIv+GL2NTmNsrLXdelVhb7muVFMnGQiIn+C2ej0OODthVNbA29X1Sf5FW8yeZLJeGIZEE99AD7jni7qxJqz50+s6HWBUemW+iSTx2MWdm8D/FXhsw/wer+iucHH1iFtb6/ismXatYKliIuW6rhn+GpdxN6q8kEXdbCNllloUky3iQZOVc9U1SOBF6jqkYXPm1X1Ry3J2AgfW4dU2SAz5PqpvuEintquGLTdmg71vFjHusteM+18yO1y+lhJKsu0Lsr3AJ9U1bvGnD8IeJSqfsuTfBPJXZTxU6c7qotdWJlMF0m9i/Jq4Fsicr6IfERE3iEi7xWRL4nI1Zjuysv9i5kJSds1xJi9kaROjoPu4HJGZlf1okwX5f6Y/eCuATYGfgf8F/B0Vf1HVQ3WNl83e4tQr26d0G5+6hBbpsmtwrS7RDOPxOW4X1fXQJb1ZHK9qp6sqh9U1RNU9buq+nvfwk1jxu33jTzuKvLbnkwyiSYbI4aiqwYllviNnRDpHyptpq1p9THpLORGsank7VK+KGNl3BhcHsOpTyq7dHedrMPVSCG+XOetGMIc+xhcJw1cJhzDmS6GTBiSWMKfKy4ZH8Ru4Mp6MuktXeqOanOrka7i279jE6ZtW9T1tAlJV8oJ192poSnrbPk4EdlaRGbaGZW3i8irfAs3jTYmmfgoFEIpkM99xfpCLAZrFNmAhaMr441dqwiVbcE9T1V/h/FqshJ4HI903RWEcZNMytLE2XET5YpNgZrKk7qBjGkyURFfs1dTT682qBpHOU7jpKyBm2m/DwW+oqp3epInGnx4QMmUY1Rh4bMAqeKZJjZGxUvbulu2WyulPRvbSu8uVZRjpKyB+x8R+SWwEDhfRHYA/uBPLD+0uXygT5TJaE03YMyZeTRtx8s4gxpTJSElXWkybJDLoemUNXDHAvsBC1V1LXA/cJg3qTwxrEx1M0KKa9JCE3Oh05c0ct2yyb4o1+PaF2Xb/m67SlkDd6mq3qWqDwKo6n3Ad/yJFQ7XyhJzwZ4x5DQy+JzUEuu+i2WvmXa+uFVO2zMRXcRtKpWVqkw0cCKys4g8FdhcRPYWkX3s50DgUa1I6JE64xeT7s34x+V2NqmmYV25qxTiPnZp7yJNumx9vLsuqVRWqjJtN4EjgNdgxt6WFk7dA5ysqt/wKt0U8kLv+Am50DmWRdZdJXT8hn5/aNacPZ+1Z+wQNA6SXuitqqeo6nOA16jqcwqfw0IbNxeEWibQNWKNC5et8VjDOIq2dDe0cfH5/hSWCYQ2bilQylWXiGwKvAiYB8wYHFfVf/EmWQlyCy5+Yq1lxypXptuk5spumnxJt+AKnAkcDqwD7it8Mj0kpdbMOJoUKi7HATP9palxa2PcOWbjW4ayBm6uqr5MVY9T1f8YfLxKlomW1JV+HGUz/7jwdzVefBFbhaCJPIN7pz2jqCMh9KVvOlrWwP1IRJ7sVZJMI6q2KmIrXGJg2qLbEHHW5XRyuW2Mi/uayDO4t00D0jdjVYeyBu5ZwDIRuU5ErhKRq0XkKp+CuaBPU8ertipi9CoR68B+1cIr1PTtvjIqjsqkQVccJNchFjl8U3aSye6jjqvqb5xLVIGmk0zaHuCNfUA5BnIcZVKkjN661u0Y8konJplYQ7YbcJD9fX/Ze0MRYw0l9JqhFN5btzbuWo6ukuPBDzH54sysp+x+cMcC7wTeZQ/NBP7Ll1Au8L0FTGoFRUxrhqriQvZJz+jTOrjZSy5NKiyhiLW7PFONsq2wF2KcK98HoKo3A1tNukFENhORK0TkZyJyjYi83x7fQ0QuF5HrReQ0EdnEHt/U/l9uz8+rG6iyTCr0hs+5HJDuGjHFRZ2Cpq3at6vJENOo4pIrF8wbMuj6iz1uqo5vxx4eH5Q1cH9UM1inACJSZivtBzBdmk8B9gIOEZF9gQ8Dx6vqAuAu4LX2+tcCd6nqfOB4e50TUtofKlbqOmNtO95iTqc2dq+I6dkDYu4en+SP1od/Rpd7HVbdgspF939qRrKsgfuqiHwW2EZEXg+cB3xu0g1quNf+nWk/ChwEnG6PnwIssr8Pt/+x5w8WESkp30QmTf9OLcFCEdoZa6wZMebCOxZCVTraHBdzuXFp8Vlln+vLAXfT60NTdpLJv2OMzteBxwPvVdVPTLtPRDYWkSuBVcC5wK+Au1V1nb1kJTDH/p4DrLDvWwesAbYvH5RqDLylp5ZgsRLbOFxbBVfMhXcIXOpBSka8LFWN7qSu0rLXlaWLa2ZnTL/EoKrnisjlg3tEZDtVvXPKPQ8Ce4nINsA3gSeMusx+j2qtbbCGQUQWA4sBNkt/x55MJpPJeKLsLMo3iMhtwFWYbXOW8cjtcyaiqncDFwH7Yro5B4Z1LnCz/b0SsxQBe34WsIEBVdUlqrpQVRfOZNOyImzArEOXR1sLTpFpXkBSpc+7t/uasBPiWbHgMk7rTHybNsN22vHUdLzsGNw/AU9S1Xmq+hhV3UNVHzPpBhHZwbbcEJHNgT8HrgUuBF5sLzsC48gZ4Cz7H3v+Ai2zCp32Zqe5IDUF6TrZ68h4Ui7YYiV0BaDp+1PT8bIG7leYxd1V2AW40Lr0+jFwrqp+C7Oe7mgRWY4ZYzvJXn8SsL09fjRwTNkXhZjU0NagbgqkXPiVHbtIKYw+dLeLejuJFNI7BRlDU9ZV197AF4DLMdP/AVDVN/sTbTp5P7i4GOU6KAZ3QqmQ4ypThZD5bfCeTrjqAj4LXABchhl/G3ySJu/o7YZBXKRaOMfSgmtr5mfW3enEuixlGjE6UQ9JWQO3TlWPVtUvqOopg49XyQJTxRvENHwqfwwZq4pHmFSp4uordJq41N2YaDNeq8bRzEWrPUmSaUJZA3ehiCwWkV1EZLvBx6tkHgjlbstnzTyGwqpJS7gNfK9lG74/hjRJiaYbzcbA2jN2qHWfywXibRFDni5LWQP31xhHyz9iffdk6WUCMdCF8Y3Y5E+la7KqfCll4JC4iqcUZ2v6CHvVd4aKq9jze5Gynkz2GPGZuEwgNlJKFFfE5l1kmFgLsxR1JURc+nBIPM3JeSwMy7nsfZ+udL+LmaxdzX8uKbvQ+9WjPr6FyzSjSQao61y5CrEYktAZ3YWLpRC7jYP/Xc5j0ZEio8LyF7vuVekZIXencClD7JTtonxa4fNnwPsw2+dkCF9A+iC0c+U2CS1/m4tvs+/M5vjalDclUglv2S7Kfyh8Xg/sDWziV7S4qOPiJtM+MWe8GD3uxBxfoRjESexxE3I/uFTKvLItuGHuBxa4FCQEgx0FypBKgrZF2S09urIfXMg9BX36+ZwmU2zu7Npcj1hljLGpH0jfjNsPriyxG/txlPVk8j+s9+y/EfBE4KuqWtqdlg+yJ5P46cLs1UwGxuty6jpeVf7i9V3xZPLvwH/YzweBA0Ibt2G6vsFlyuQ4G01sXY85nSZTxtt+LFTd7bsKMYZ3HGUN3E3A5ap6sar+ELhDROZ5k6oGqS3a7hN14qwPha1PXaozhT+vF0yLSUMsuZwylDVwXwMeKvx/0B5LnpCZNPRYgyuqjGWWJfUMGkP6+Y7DlNMoVPq4zCvjvKfEoHuxUNbAzVDVPw7+2N9RzKIsO9lhHCEzaVs+HH3P3pt16PKx51IuBJvgOtwuCq3YC76YfU1Oo6zsdV16VaGveW4UZQ3cahF5eN2biBwO3O5HpGoUEzMn7HqKGa6uK6QYFqNmDC7SIpb8MU4nYpGvDmWdLYfe8LQJKeblsgbujcD/FZEVIrICs2npYn9iucPH1iFtb6/ismWaciEyDRct1XHP8JW5Uyw0mtJFHWyjZRaaFNOt1DKBhy8W2dLec48/kcqTlwmsJ9apyj7lijXMmf6x5uz5E7vqQ+Izn3RimYCIzBKRjwIXYbbO+Q8RmeVVskwluljQ97F1k+k2oZxi95WyXZSfB+4BXmo/vwO+4EuoTAa6u3GnC7Lxj4uyXZQxTB5L/d1VKGvgHquqx6rqDfbzfiCp7XIymS6RunGPZW+ztt+duj/IVPaAHFDWwP1eRJ41+CMi+wO/9yNSe6RSC/FJynGQsuyhCR13Me2C7muG6qg4TsEwxORbtillDdzfAZ8UkRtF5DfAf2JmViZNaonlg5TjIGXZQxNz3Pk2vj6eP2oBd8xxPIlU5R5F2e1yrlTVpwB7Ak9W1b1V9Wd+RfNP6FpsJtNFYt+I08fzR82gTLV8SVXuUUw0cCJydPEDvA54XeF/JyiboDGNG3SFJnGY498NoXb57jq+48GX/ncp/aa14Layn4WYbso59vNGzJY5naBO/3leg7WeJhmtSRy6iv+2F+77pqpzg6zHG1I1vVPSjz4x0cCp6vvtjMnZwD6q+jZVfRvwVGBuGwKGoskU9azs04nJt2KZAj4lI5CXVzTH1xYyVZwtV9HvtsYVU6PsJJNHA38s/P8jMM+5NI5wtQtv3Zp96AKkbQNbJ7wp+1bMFZh4CZU203YGGZyv4u1k2k7uvvU/Vs8sVShr4L4EXCEi7xORY4HLgVP8idWMsgk/TSnLtNJCG7NRZCes1ahakYkxzYv48L+aCm12W5dl9pJLvThZTkknQ1F2FuUHgCOBu4C7gSNV9YM+BauLK2/5fevm6fOAdZe6KMuMDdcNS5cN4zB97h2IQQZXVHK2HBtNnS13ZaJIzOGIWbYBbcqYQnxk/DGc/inqQ9GxdCecLXeV1BRrHF0JRyja9A/YZlp1qSbeFVx6cAmVviltDdRLA5czfmYadXVk9pJLH743tJ75HI8KHbYBffFh6YI2Zx3HQicNnKtadKrro2KUKTWaLAMZ3JtSQTCJUeGIJWzDcrSp+8NdjeMozqJ0wagJbmWeH0uatUknDVzZwsmFIYxxwL6PitwmOX7jrUSFWp86c9Hqsedim0UZa9r5oJMGbhJFRUjdg3kM9Cmz9AFXa0hjxKfMIdaMTTKqk0gx7erSOwOXcUufMksfyOmZDmUme/iqgKZSse2kgRsX+akkim9yPJQjx1M4XMd9XYfqrp/vkjKemHxVWFKpCPV6HVzXCLWmZtJ7U1znk8lUpbg2rE/kdXARM23mU917Q5ENST1SnS07jhR1NzaqxlGItWE5HafTawOXyWQyme7SawPXJ1+UPscWYo4LV/LHEEZXMxxjCEvs+NouJ9MuvTZwsL7Q6Hpzv24GTD3jpi5/EZ9h6br++yZEN3eXdNsX3g2ciGwsIj8VkW/Z/3uIyOUicr2InCYim9jjm9r/y+35eU3fXaX2XlVZYnZfFJqqnhtyvG1ICnv6ZarRtThOId+20YJ7C3Bt4f+HgeNVdQFm+53X2uOvBe5S1fnA8fa6RvhUqJjdF4WmqueGVOOtr92+mQ1p6v4vBWMxTAo66tXAichc4C+BE+1/AQ4CTreXnAIssr8PZ/0mqqcDB9vrvdG1WZShSD0u2t653XfBkHW3OVXjqOn4aB2dyOk4Hd8tuBOAdwAP2f/bA3er6jr7fyUwx/6eA6wAsOfX2Ou9Ecskk2FFjX3a+vC7m8RjCKrIX+WaKqw5e36l41Xo+iSTNnQ/9kkm2biVw5uBE5EXAKtUdVnx8IhLtcS54nMXi8hSEVm6lgcayejDw3cdxu0RNemZoRZ0j3p3apkthgJ+3KLgri8WrlOZGyaG9BumbsWkybZMLkktD5fFZwtuf+AwEbkROBXTNXkCsI2IzLDXzAVutr9XArsB2POzgDuHH6qqS1R1oaounMmm3oSv2s3jI9PFlpG72o0Se4u5KjF3Ubrc8NMnbS30jiX8scjhGm8GTlXfpapzVXUe8HLgAlV9JXAh8GJ72RHAmfb3WfY/9vwFGtCPWKzdPD4LJ9+1yViNRCrr4MoSg+769iXpW5diTe9Y81CshFgH907gaBFZjhljO8kePwnY3h4/GjjGtyBtKbFLpSzjYNXXs5vi4/kxZvhRhXEscrYlR5m0riJLmZZfTC3TcTSVMQbDG4sul6EVA6eqF6nqC+zvG1T16ao6X1VfoqoP2ON/sP/n2/M3+JarrVmUbSplyLG5ELgIr+suylGFcZvpMm3sNpYCynWc+Jz45er6GAxUU1IKQ+89mWQymUymm/TawPleJhBLTdklLteDxUIeg3NDzPpeVbY6ywRiDn9f6bWB801KhWJZuhimjBti1o1J+xVWYdz1a86e3zj8vo2wi3emRq8NXPZk4obU4yIvE+gvVQ3fuOtd7Afnwh+u73emRq8NXCyeTFIn9ZpknS7KmI1EU92NOWxtEbsnk9CkoiO9NnBlcZGYXWsluCa1Mc0uF2hdCptPh9hFXLhYq8rMRatLX9vXrXo6beBcJaqLxCxTa87+7CZTdGGWmuyZMLTlEDuEi7Uq3aKpGCTXdNrA+eyKcVXAjvPv2AZtvNNH1960dWXZ+K0nx0V8pJAmKchYhk4bOJ+4Mg5dr1k19dnZFWe8oehaXDQteOvc79sRQF0Z2t7vMkV6beC6kohdJhWv6V2p8ZahGNY2wl18R1N9qHN/mXuqjIfVITbXZKnQawPng6x0jyS2SsSoBbkpTbd22a3uwrl2iG7uGAkxBleMl1zujCYbOMe00eIYHEtBqWOUMZUtW0bRRNaUw53ZEJct2ybvjpleGbi2t9yoQ5kxq8GxVAso31uphHpGrKTeLZtC2qQg4yRCeFFpg84buEm1nLr+43yuaetDX7svL/JN1jxNe0bKRsJXYdRWIZdKYdo2LuOlq3HceQPnwyNJFc8XKY3vpI7P9YqpGwkI23IOWUlzUSGddt73JJNJdK0C7BIJuGl2Y7aW7fQZcnBoMTITqLOAPcSi90wmU53z9PRlqrowtBzj6HwLLtOctmuIfdzOpS1yHHQHl+7BuqoXSRu4dbO3CC1Ca8TujHgUsWWa3CpMu0s080hc7GAwIMROBm2QtIGbcft9I4+7dqPV9BoXVFHAWJSvqwYllviNnRDpHyptpm295VKuUe79utLL4ppOjsHlMZz6hPSNmVlP1uFqpBBfrvNWDGGOfQyukwYuE47hTBdDJgxJLOHPFZeMD2I3cEl3UbZBl7qjUl5zFQsxL4idJNu0HRgyzehKOdG1raiSNnBtTDLxUSiEUqBxYemSQvsmFoM1imzAwtGV8cauVYSSNnDjJpmUZdrAcN17pxGbAjWVJ3UDGdNkoiK+Zq+mnl5tUDWOcpzGSdIGzic+PKBkyjHJwbQPqnimiY06+4T5cAgeUyUhJe9BXaoox0ivDFybywf6RJmM1nRDyJyZRxODF/my3VrZd+WGNBk2yOXQdHpl4FxtF5LimrTQxFzo9CWNXLdssi/K9bj2Rdm2v9uu0isDVwbXyhJzwZ4x5DQy+JzUEjKOXbQup50vbnja9kxEF3GbSmWlKr02cHXGLybdm/GPy+1sUk1Dl1sxjTvv0s9hl2nSZevj3XVJpbJSlV4bOJe7I2faocp2NtMKgFTTsA25iy2ScYSuIIR+P4TVoZmLVkcRBzHTawMXaplA14g1Lly2xmMN4yja0t3QFQSf709hmcDaM3YIngaxk111ZbwSi6uqYWKVK9NtUnNlN02+7Kor0zlSas2Mo0mh4nIcMNNfmhq3NsadYza+ZcgGLlOZ1JV+HGUzf5VxwMx4YqsQNJFncG+Vcd8Q+tI3Hc0GriNUbVXEVrjEwLRFtyHirMvp5HLbGBf3uZh01qYB6ZuxqkOnDVyfpo5XbVXE6FUi1oH9qoVXqOnbfaXODNpx9/kmlvIlFjl802kDN02Bm6yDq0NflKous5dc2tilVwzEKlefiMGF2ahrXMqV/VhOp7MGLkZjElKpQsWHi0FtF7LHqA8hyPHgh5h8cWbW01kD53sLmNQKipRbpi5kn/SMPq2Dq9pK7iuxdpdnqtFZA1eGSYXe8DmXA9JdI6a4qFPQtFX7djUZYhpVXHLlgnlDBl2JscdN1fHt2MPjg14YuJT2h4qVus5Y2463mNOpjd0rYnr2gJi7xyeNw/vwz+hyr8Oq49Uuuv9TM5K9MHCTpn+nlmChCO2MNdaMGHPhHQuhKh1tjou5nPBRfFbZ5/pywN30+tB4NXAicqOIXC0iV4rIUntsOxE5V0Sut9/b2uMiIh8XkeUicpWI7ONTtoG39NQSLFZiG4drq+CKufAOgUs9SMmIl6Wq0Z3UVVr2urJ0cc1sGy2456jqXgV/ZccA56vqAuB8+x/g+cAC+1kMfLoF2TKZTCbTUUJ0UR4OnGJ/nwIsKhz/ohouA7YRkV18CTHr0OXR1oJTZJoXkFTp8+7tvibshHhWLLiM0zoT36bNsJ12PDUd923gFPieiCwTkcX22E6qeguA/d7RHp8DrCjcu9Iem0pbs9NckJqCdJ3sdWQ8KRdssRK6AtD0/anpuG8Dt7+q7oPpfjxKRA6YcK2MOLbBXj4islhElorI0rU8AISZ1NDWoG4KpFz4lR27SCmMPnS3i3o7iRTSOwUZQ+PVwKnqzfZ7FfBN4OnAbYOuR/u9yl6+EtitcPtc4OYRz1yiqgtVdeFMNm0kX5V1cFXP94lBXKSa4WLxQtHWRqRZd6eT6uzCrs8eroo3AyciW4jIVoPfwPOAnwNnAUfYy44AzrS/zwJebWdT7gusGXRl+iLv6O2GQVzEksmrEksLrq2Zn1l3pxPrspRpxOhEPSQ+W3A7AT8QkZ8BVwDfVtVzgA8BzxWR64Hn2v8AZwM3AMuBzwFv8ijbVFzWgn0qfwwZq0lLOBWquPoKnSZdbcG1Ga9V42jmotWeJMk0QVQ3GOZKhq1lO32GHFz6+ti3h59GrPJPkisGmWOQITOeLqRP3TCkGPaizOfp6csKS8CioxeeTCBNRRomNvlT6ZqsKl/oFlgq+BgzTCXu2xovnfTOUHEVe34v0hsDl1KiuCI27yLDxFqYpagrIeLSh0PiaU7OY2FYzmXvq+aXwsVM1q7mP5f0xsD1kSYZoK5z5SrEYkhCZ3QXLpZC7DYO/nc5j0VHiowKy1/sulelZ4TcncKlDLGTDZwDQheQPgjtXLlNQsvf5uLb7DuzOb425U2JVMKbDVxJ6ri4ybRPzBkvRo87McdXKAZxEnvchNwPLpUyr9cGbrCjQBlSSdC2KLulR1f2gwu5p6BPP5/TZIrNnV2b6xGrjDE29QPpm3H7wZUldmM/jl4tE8i0Txdmr2YyMF6XU9fxqvLnZQIByC5q4iXH2Whi63rM6TSZMt72Y6Hqbt9ViDG84+iMgcsuauKl7gLYruNTl+pM4c/rBdNi0hBLLqcMnTFwdQmZSUOPNbiiylhmWVLPoDGkn+84TDmNQqWPy7yy9owdRh6PQfdiIXkDV3aywzhCZtK2fDj6nr0369DlY8+lXAg2wXW4XRRasRd8MfuanEZZ2ccZJZf0Nc+NIk8y6SixDIinPgCfcU8XdWLN2fMnVvS6wKh0i32SSdIGTkTuAa4LLYcjZgO3hxbCETkscZLDEicph2V3VRi0/EsAAAiHSURBVPXfLK3JjNACNOS6mGsPVRCRpTks8ZHDEic5LJkyJD8Gl8lkMpnMKLKBy2QymUwnSd3ALQktgENyWOIkhyVOclgyU0l6kkkmk8lkMuNIvQWXyWQymcxIkjVwInKIiFwnIstF5JjQ8kxDRD4vIqtE5OeFY9uJyLkicr393tYeFxH5uA3bVSKyTzjJN0REdhORC0XkWhG5RkTeYo8nFx4R2UxErhCRn9mwvN8e30NELrdhOU1ENrHHN7X/l9vz80LKP4yIbCwiPxWRb9n/SYYDQERuFJGrReRKEVlqjyWnYwAiso2InC4iv7T5Zr9Uw5ISSRo4EdkY+CTwfOCJwCtE5IlhpZrKycAhQ8eOAc5X1QXA+fY/mHAtsJ/FwKdbkrEs64C3qeoTgH2Bo2z8pxieB4CDVPUpwF7AISKyL/Bh4HgblruA19rrXwvcparzgePtdTHxFuDawv9UwzHgOaq6V2EafYo6BvAx4BxV/RPgKZg0SjUs6aCqyX2A/YDvFv6/C3hXaLlKyD0P+Hnh/3XALvb3Lph1fQCfBV4x6roYP8CZwHNTDw/wKOAnwDMwC29nDOsb8F1gP/t7hr1OQstu5ZmLKSgPAr4FSIrhKITnRmD20LHkdAzYGvj1cPymGJbUPkm24IA5wIrC/5X2WGrspKq3ANjvHe3xZMJnu7b2Bi4n0fDYbr0rgVXAucCvgLtVdZ29pCjvw2Gx59cA27cr8VhOAN4BPGT/b0+a4RigwPdEZJmILLbHUtSxxwCrgS/Y7uMTRWQL0gxLUqRq4GTEsS5NB00ifCKyJfB14K2q+rtJl444Fk14VPVBVd0L0wJ6OvCEUZfZ7yjDIiIvAFap6rLi4RGXRh2OIfZX1X0wXXZHicgBE66NOTwzgH2AT6vq3sB9rO+OHEXMYUmKVA3cSmC3wv+5wM2BZGnCbSKyC4D9XmWPRx8+EZmJMW5fVtVv2MPJhgdAVe8GLsKMK24jIgNXdkV5Hw6LPT8LuLNdSUeyP3CYiNwInIrppjyB9MLxMKp6s/1eBXwTU/lIUcdWAitV9XL7/3SMwUsxLEmRqoH7MbDAzhDbBHg5cFZgmepwFnCE/X0EZixrcPzVdjbVvsCaQVdGDIiIACcB16rqRwunkguPiOwgItvY35sDf46ZAHAh8GJ72XBYBmF8MXCB2oGSkKjqu1R1rqrOw+SHC1T1lSQWjgEisoWIbDX4DTwP+DkJ6piq3gqsEJHH20MHA78gwbAkR+hBwLof4FDgfzHjJe8OLU8Jeb8C3AKsxdTQXosZ8zgfuN5+b2evFcws0V8BVwMLQ8s/FJZnYbpMrgKutJ9DUwwPsCfwUxuWnwPvtccfA1wBLAe+Bmxqj29m/y+35x8TOgwjwnQg8K2Uw2Hl/pn9XDPI4ynqmJVvL2Cp1bMzgG1TDUtKn+zJJJPJZDKdJNUuykwmk8lkJpINXCaTyWQ6STZwmUwmk+kk2cBlMplMppNkA5fJZDKZTpINXKYzWI/tb2rxfbsMvPa38K4bRWR2hevnSWHniobv3kFEznHxrEymTbKBy3SJbYBKBs4upq2bD44GPlfz3qiwO3SMRFVXA7eIyP4tipTJNCYbuEyX+BDwWLt/2EcAROTtIvJju6/WYK+3eXZPrk9hdg/YTUTuFZEPW8e+54nI00XkIhG5QUQOG/O+FwHn2GdeLiJPGpyw9z7V7vl1hn3/ZSKypz2/pYh8Qcx+Z1eJyIvs8U+LyFIp7E1X4O1i9q67QkTm2+tPFpEXF95777CQNrzfF5Gf2M8z7fEDxezr99/A1SLyr2L39rPnPyAib7Z/zwBeWTIdMpk4CL3SPH/yx9WHDbcjeh6wBOMZYiPMFjIH2OseAvYtXKvA8+3vbwLfA2Zi9u66csS79gCWFf7/I/B++3sX4H/t708Ax9rfBw2ehdl/7YTC/dva74E3i40xfjH3tP9vZL03j1ez3lPJycCLC8+5dzguMNsAbWZ/LwCW2t8HYhz/7lG45yf290YYTxrb2/9zgKtDp3H+5E+Vz8AJaybTRZ5nPz+1/7fEFPA3Ab9R1csK1/4R2xrDuEd6QFXXisjVmIJ/mF0wW6AM+Cpmq51jgZdi3GCBcWv2IgBVvUBEtheRWRifly8f3Kyqd9mfL7Vbw8yw73gixr0TGHdvg+/jS4R/wEzgP0VkL+BB4HGFc1eo6q+tDDeKyB0isjewE/BTVb3DXrcK2LXCOzOZ4GQDl+kyAnxQVT/7iINmD7v7hq5dq6oDv3UPYXb6RlUfKnjjL/J7jD9H7HW/tcZhT+BlwBsKMgyj9vgj/OSJyB7APwFPU9W7ROTk4juGrh/8XocdarBOsDcZ8b5/BG7DtEY3Av5QODccDycCrwF2Bj5fOL4ZJsyZTDLkMbhMl7gH2Krw/7vA34rZtw4RmSMiO468szr/y4Ytu1MxG47OUtWr7bFLsGNXInIgcLuavfO+B/z94EYR2Raz8/N9wBoR2QmzD1qRlxW+L7W/bwSean8fjmmtDTMLuEVVHwL+BtP9OY5vAocAT8PE34DHYZxRZzLJkFtwmc6gqneIyA/t9PjvqOrbReQJwKWmccO9wKsw3XRN33WfiPxKROar6nJ7+HTgY8C/Fi59H2Yn56uA+1m/Pcq/AZ+0sj6IGb/7hoj8FOM9/wbgh0Ov3VRELsdUTF9hj30OOFNErsB4pB9ukQF8Cvi6iLwEs33OqGsG4fqjiFyI2Qm8GE/PAb497r5MJkbybgKZTE1E5IXAU1X1PaFlcYVdMvET4CWqen3h+CXA4YWxwkwmenIXZSZTE1X9JqaLsBOIyBMx+8OdP2TcdgA+mo1bJjVyCy6TyWQynSS34DKZTCbTSbKBy2QymUwnyQYuk8lkMp0kG7hMJpPJdJJs4DKZTCbTSbKBy2QymUwn+f82HNWvKQ/CTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ed07769cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "compute the term-by-document matrix and the the dictionary from the collection of \n",
    "tweets collected for the first keyword\n",
    "'''\n",
    "k1_termdoc, k1_vocab = construct_termdoc(k1_tweets_processed)\n",
    "\n",
    "# print out the term-by-document matrix\n",
    "print(k1_termdoc)\n",
    "# print out the first 5 vocabularies\n",
    "print(' '.join(k1_vocab[:5]))  # print out only the first 5 vocabs\n",
    "\n",
    "# visualise the term-by-document matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.imshow(k1_termdoc)\n",
    "ax.set_xlabel('term (vocabulary)')\n",
    "ax.set_ylabel('documents (tweets)')\n",
    "ax.set_title('Term-by-Document matrix from tweets collected for keyword \\\"{}\\\"'.format(keywords[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. Next, we would like to compute the pairwise distances between every two tweets. This will help us to see how similar tweets are. This is a computational task that would be *not* possible to do if we use the raw tweets.\n",
    "\n",
    "However, with the term-by-document matrix, each tweet now is vector and corresponds to a row in the term-by-document matrix. Hence, we can use the distance between vectors to compute the distance between tweets. This is also known as the **vector space model** in information retrieval literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.10**. Your tasks are:\n",
    "\n",
    "1. Define a function to compute and return the Euclidean distance between two vectors as we have learned from the class notes. **(5 marks)**\n",
    "\n",
    "2. Construct function that returns a distance matrix ***euclidean_distance_matrix*** whose element (i,j) stores the Eulidean distance between tweet i-th and i-jth. **You will need this function for subsequent task**. **(5 marks)**\n",
    "\n",
    "**[Total mark: 10]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "def Euclidean_distance(x,y):\n",
    "    '''\n",
    "    Compute and return the Euclidean distance between two vectors x and y\n",
    "    '''\n",
    "    # INSERT YOUR CODE HERE\n",
    "    dist = (np.array(x) - np.array(y))*(np.array(x) - np.array(y))\n",
    "    return np.sqrt(dist.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'j' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-514-332972c3fd30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mk1_vocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mk1_vocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mcompute_euclidean_distance_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk1_termdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-514-332972c3fd30>\u001b[0m in \u001b[0;36mcompute_euclidean_distance_matrix\u001b[1;34m(termdoc)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# INSERT YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEuclidean_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mk1_vocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mk1_vocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mcompute_euclidean_distance_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk1_termdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'j' is not defined"
     ]
    }
   ],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "The function takes the termdoc matrix as the input and compute a variable called \"euclidean_distance_matrix\", \n",
    "which is a matrix whose element (i,j) stores the Eulidean distance between tweet i-th and i-jth.\n",
    "\n",
    "Hint: you should store the Euclidean distance matrix in a numpy array for easier implementation in subsequent tasks\n",
    "'''\n",
    "\n",
    "def compute_euclidean_distance_matrix(termdoc):\n",
    "    # INSERT YOUR CODE HERE\n",
    "    np.array(Euclidean_distance)\n",
    "    j = k1_vocab\n",
    "    i = k1\n",
    "compute_euclidean_distance_matrix(k1_termdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.11**. Now you need to compute the distance matrix for **k1_termdoc** and then visualise this distance matrix.\n",
    "\n",
    "**[Total mark: 10]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "# compute the distance matrix for k1_termdoc using the function \"compute_euclidean_distance_matrix\"\n",
    "k1_euclidean_distances = # INSERT YOUR CODE HERE\n",
    "\n",
    "# Visualise the distance matrix for this keyword\n",
    "# Hint: using imshow() function\n",
    "# INSERT YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.12**. Similar to the example above for the first keyword, your task is to write codes in the cell below to compute the term-by-document matrix and the vocabulary for tweets stored in ***k2_tweets_processed***, print out the first **5** vocabularies and visualise this term-by-document matrix.\n",
    "\n",
    "[**Total mark: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your codes to compute the term-by-document matrix and the vocabulary for tweets stored \n",
    "in k2_tweets_processed\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n",
    "\n",
    "\n",
    "'''\n",
    "Write your code print out the first 5 vocabularies \n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n",
    "\n",
    "\n",
    "'''\n",
    "Write your code to visualise the term-by-document matrix\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Instruction 2.13***. Next, your task is to write codes in the cell below to calculate the pairwise distance matrix for tweets collected for **second** keyword. Store this distance matrix in the variable named ***k2_euclidean_distances*** and **visualise** this matrix.\n",
    "\n",
    "[**Total mark: 10**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "# compute the Euclidean distance matrix using compute_euclidean_distance_matrix() function\n",
    "k2_euclidean_distances = # INSERT YOUR CODE HERE\n",
    "       \n",
    "# Visualise the distance matrix for this keyword\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.14**. Similarly, your task is to write codes in the cell below to compute the term-by-document matrix and the vocabulary for tweets stored in ***k3_tweets_processed***, print out the first **5** vocabularies and visualise this term-by-document matrix.\n",
    "\n",
    "[**Total mark: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your codes to compute the term-by-document matrix and the vocabulary for tweets stored \n",
    "in k3_tweets_processed\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n",
    "\n",
    "\n",
    "'''\n",
    "Write your code print out the first 5 vocabularies \n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n",
    "\n",
    "\n",
    "'''\n",
    "Write your code to visualise the term-by-document matrix\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Instruction 2.15***. Next, your task is to write codes in the cell below to calculate the pairwise distance matrix for tweets collected for **third** keyword. Store this distance matrix in the variable named ***k3_euclidean_distances*** and visualise this matrix.\n",
    "\n",
    "[**Total mark: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "# compute the Euclidean distance matrix using compute_euclidean_distance_matrix() function\n",
    "k3_euclidean_distances = # INSERT YOUR CODE HERE\n",
    "\n",
    "# Visualise the distance matrix for this keyword\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2C: Data Clustering\n",
    "\n",
    "Thus far in this assignment, we have collected tweets for each keyword and analyse them seperately. We have constructed the term-by-document matrix for each collection of tweets seperately. A fundemantal and common task in data science, analytics, machine learning, science and engineering is **clustering**. This is also known as unsupervised learning or exploratory data analysis as we have learned in our classes.\n",
    "\n",
    "This part of this assignment will use the Kmeans algorithm learned in our classes to cluster the **entire** colllection of tweets collected for **all** keywords. To do so, we need to compute the **distance** between **any** two pair of tweets. This requires us to compute a **joint** term-by-document matrix for all tweets.\n",
    "\n",
    "The reason that we **cannot** use the individual term-by-document matrices computed earlier (e.g.,***k1_termdoc, k2_termdoc, k3_termdoc***) for this task is because they have different dictionary sizes. Hence, tweets collected for different keywords have been represented by vectors of different dimension. \n",
    "\n",
    "The following piece of codes will help you to inspect these dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Dimension of the term-by-document matrix for keyword \\\"{}\\\":'.format(keywords[0]))\n",
    "print('{} x {}\\n'.format(k1_termdoc.shape[0],k1_termdoc.shape[1]))\n",
    "\n",
    "print('Dimension of the term-by-document matrix for keyword \\\"{}\\\":'.format(keywords[1]))\n",
    "print('{} x {}\\n'.format(k2_termdoc.shape[0],k2_termdoc.shape[1]))\n",
    "\n",
    "print('Dimension of the term-by-document matrix for keyword \\\"{}\\\":'.format(keywords[2]))\n",
    "print('{} x {}\\n'.format(k3_termdoc.shape[0],k3_termdoc.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. First, we need to gather all tweets together into a new variable named **all_tweets_processed** using the piece of codes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets_processed = k1_tweets_processed + k2_tweets_processed + k3_tweets_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.16**. Your task is to write codes in the cell below to compute the term-by-document matrix and the vocabulary for all tweets stored in ***all_tweets_processed***, print out the first 5 vocabularies and visualise this term-by-document matrix.\n",
    "\n",
    "[**Total marks: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your codes to compute the term-by-document matrix and the vocabulary for all tweets stored \n",
    "in all_tweets_processed\n",
    "'''\n",
    "\n",
    "all_termdoc, all_vocab = # INSERT YOUR CODE HERE\n",
    "\n",
    "'''\n",
    "Write your code print out the first 5 vocabularies \n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n",
    "\n",
    "\n",
    "'''\n",
    "Write your code to visualise the term-by-document matrix\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.17**. Next, your task is to write codes in the cell below to calculate the pairwise distance matrix for all tweets collected. Store this distance matrix in the variable named ***all_euclidean_distances*** and visualise this matrix.\n",
    "\n",
    "[**Total mark: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "# compute the Euclidean distance matrix using compute_euclidean_distance_matrix() function\n",
    "all_euclidean_distances = # INSERT YOUR CODE HERE\n",
    "        \n",
    "# Visualise the distance matrix for this keyword\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. Next, we use Kmeans algorithm to cluster all tweets stored in term-by-document matrix ***all_termdoc***. An important requirement for the Kmeans is the specification of the number of clusters which will be specified the variable **n_clusters**.\n",
    "\n",
    "The following piece of codes will initialise a ***kmeans*** object to be used for subsequent clustering task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initialise a kmeans object  from scikit-lean package\n",
    "'''\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=5, max_iter=300,\n",
    "                verbose=True, tol=0.00001, random_state=123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.18**. Your task is to use the variable ***kmeans*** to perform clustering on the data stored in the variable ***all_termdoc***.\n",
    "\n",
    "[**Total mark: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "'''\n",
    "Use the variable kmeans to perform clustering on the data stored in the variable all_termdoc\n",
    "Hint: revise the practical session on Kmeans algorithm or check out the documentation from scikit-learn\n",
    "for Kmeans algorithm.\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.19**. Write your codes to print out the cluster centers.\n",
    "\n",
    "[**Total mark: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your codes to print out the cluster centers.\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.20**. Write your codes to print out the first **500** cluster labels assigned to the first 500 tweets.\n",
    "\n",
    "[**Total marks: 5**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your codes to print out the first **500** cluster labels assigned to the first 500 tweets.\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.21**. Next, we would like to obtain the quality of our clustering results. Write your code to obtain the labels of tweets for each keyword and store the labels in three new variables ***k1_labels***, ***k2_labels*** and ***k3_labels***, respectively.\n",
    "\n",
    "**[Total marks: 5]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "'''\n",
    "Write your code to obtain the labels of tweets for each keyword\n",
    "and store the labels of the first keyword in ***k1_labels***, \n",
    "the labels of the second keyword in ***k2_labels*** and\n",
    "the labels of the third keyword in ***k3_labels***.\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.22**. Then, we examine what is the proprotion of tweets from different keywords (or categories) appear in the **first** cluster. Remember that **0** is the label for the first cluster (**1** for the second and **2** for the third clusters). Your tasks are:\n",
    "\n",
    "1. Write your code to obtain the list of tweet indices of each keyword that are assigned to the first cluster. **(5 marks)**\n",
    "\n",
    "2. Plot a bar chart to visualise the number of tweets of each keyword that are assigned to the first cluster. **(5 marks)**\n",
    "\n",
    "**[Total mark: 10]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Write your code to obtain the list of tweet indices of each keyword that are assigned to the first cluster.\n",
    "Hint: you might want to use numpy.where function.\n",
    "'''\n",
    "# obtain the list of tweet indices of keyword k1 that are assigned to the first cluster\n",
    "# means that to find tweet indices that have label 0 in k1_labels\n",
    "k1_idx_label0 = # INSERT YOUR CODE HERE\n",
    "\n",
    "# obtain the list of tweet indices of keyword k2 that are assigned to the first cluster\n",
    "# means that to find tweet indices that have label 0 in k2_labels\n",
    "k2_idx_label0 = # INSERT YOUR CODE HERE\n",
    "\n",
    "# obtain the list of tweet indices of keyword k3 that are assigned to the first cluster\n",
    "# means that to find tweet indices that have label 0 in k3_labels\n",
    "k3_idx_label0 = # INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "'''\n",
    "Plot a bar chart to visualise the number of tweets of each keyword that are assigned to the first cluster.\n",
    "Hint: you need to plot a bar chart with three bars, \n",
    "each bar represents the number of tweets of each keyword that are assigned to the first cluster.\n",
    "'''\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.23**. Similarly, write your codes to compute the the proprotion of tweets from different keywords (or categories) appear in the **second** cluster and plot a bar chart visualise this information.\n",
    "\n",
    "[**Total mark: 8**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "# obtain the list of tweet indices of keyword k1 that are assigned to the second cluster\n",
    "# means that to find tweet indices that have label 1 in k1_labels\n",
    "k1_idx_label1 = # INSERT YOUR CODE HERE\n",
    "\n",
    "# obtain the list of tweet indices of keyword k2 that are assigned to the second cluster\n",
    "# means that to find tweet indices that have label 1 in k2_labels\n",
    "k2_idx_label1 = # INSERT YOUR CODE HERE\n",
    "\n",
    "# obtain the list of tweet indices of keyword k3 that are assigned to the second cluster\n",
    "# means that to find tweet indices that have label 1 in k3_labels\n",
    "k3_idx_label1 = # INSERT YOUR CODE HERE\n",
    "\n",
    "# Plot a bar chart to visualise the number of tweets of each keyword that are assigned to the second cluster\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction 2.24**. Similarly, write your codes to compute the the proprotion of tweets from different keywords (or categories) appear in the **third** cluster and plot a bar chart visualise this information.\n",
    "\n",
    "[**Total mark: 8**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL\n",
    "\n",
    "# obtain the list of tweet indices of keyword k1 that are assigned to the third cluster\n",
    "# means that to find tweet indices that have label 2 in k1_labels\n",
    "k1_idx_label2 = # INSERT YOUR CODE HERE\n",
    "\n",
    "# obtain the list of tweet indices of keyword k2 that are assigned to the third cluster\n",
    "# means that to find tweet indices that have label 2 in k2_labels\n",
    "k2_idx_label2 = # INSERT YOUR CODE HERE\n",
    "\n",
    "# obtain the list of tweet indices of keyword k3 that are assigned to the third cluster\n",
    "# means that to find tweet indices that have label 2 in k3_labels\n",
    "k3_idx_label2 = # INSERT YOUR CODE HERE\n",
    "\n",
    "# Plot a bar chart to visualise the number of tweets of each keyword that are assigned to the third cluster\n",
    "# INSERT YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF ASSIGNMENT 2 NOTEBOOK\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
